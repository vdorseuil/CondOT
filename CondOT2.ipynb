{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import scipy.stats as stats\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import optim\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from icnnet import ICNNet\n",
    "from mydataset import MyDataset, get_gaussian_dataset, get_gaussian_transport_dataset\n",
    "from toy_data_dataloader_gaussian import generate_gaussian_dataset, get_dataset, generate_dataset\n",
    "from train_picnn import PICNNtrain\n",
    "from train_wasserstein import train_wasserstein\n",
    "from train_makkuva import train_makkuva, train_makkuva_epoch\n",
    "from visualization import plot_transport\n",
    "from gaussian_transport import get_gaussian_transport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __Generate dataset__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset = get_dataset(d=2, r=100, N=500) #valou\n",
    "#dataset = generate_gaussian_dataset(d=2, r=400, N=10000) #thomas\n",
    "dataset = generate_dataset(d=2, r=1000, N=500)\n",
    "gaussian_dataset = get_gaussian_dataset(dataset)\n",
    "gaussian_transport_dataset = get_gaussian_transport_dataset(gaussian_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean(batch):\n",
    "    means = torch.mean(batch, dim=1)\n",
    "    average_mean = torch.mean(means, dim=0)\n",
    "    return(average_mean)\n",
    "\n",
    "def get_covariance(batch):\n",
    "    n = batch.size(1) - 1\n",
    "    mean = torch.mean(batch, dim=1, keepdim=True)\n",
    "    batch = batch - mean  # Centering the data\n",
    "    cov = torch.matmul(batch.transpose(1, 2), batch) / n\n",
    "    return(torch.mean(cov, dim=0))\n",
    "\n",
    "mean1 = get_mean(dataset.X)\n",
    "cov1 = get_covariance(dataset.X)\n",
    "mean2 = get_mean(dataset.Y)\n",
    "cov2 = get_covariance(dataset.Y)\n",
    "\n",
    "def init_z_f(x):\n",
    "    #return (1/2) * torch.norm(x, dim=-1, keepdim=True)**2\n",
    "    return(get_gaussian_transport(u=x, cov1 = cov1, cov2 = cov2, m1=mean1, m2=mean2))\n",
    "\n",
    "def init_z_g(x) :\n",
    "    #return (1/2) * torch.norm(x, dim=-1, keepdim=True)**2\n",
    "    return(get_gaussian_transport(u=x, cov1 = cov2, cov2 = cov2, m1=mean2, m2=mean1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __Initialization__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __PICNN training__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 2\n",
    "layer_sizes = [input_size,64, 64, 64,64, 1]\n",
    "n_layers = len(layer_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "# def get_embedding(C, c):\n",
    "#     scalar_product = torch.matmul(c.float(), C.t().float())\n",
    "#     embedding = F.softmax(scalar_product, dim=1)\n",
    "#     return(embedding)\n",
    "\n",
    "context_layer_sizes = [12] * n_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_init_f = ICNNet(layer_sizes = layer_sizes, context_layer_sizes=context_layer_sizes, init_bunne = 'TR')\n",
    "model_init_g = ICNNet(layer_sizes = layer_sizes, context_layer_sizes=context_layer_sizes, init_bunne = 'TR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training f\n",
      "Epoch 1/400 Loss: 10620.298828125\n",
      "Epoch 2/400 Loss: 2087.87353515625\n",
      "Epoch 3/400 Loss: 446.8060302734375\n",
      "Epoch 4/400 Loss: 100.56060409545898\n",
      "Epoch 5/400 Loss: 20.45000648498535\n",
      "Epoch 6/400 Loss: 2.7931596636772156\n",
      "Epoch 7/400 Loss: 1.0180346965789795\n",
      "Epoch 8/400 Loss: 3.0920804738998413\n",
      "Epoch 9/400 Loss: 5.649677515029907\n",
      "Epoch 10/400 Loss: 7.882863759994507\n",
      "Epoch 11/400 Loss: 9.686431884765625\n",
      "Epoch 12/400 Loss: 11.0792818069458\n",
      "Epoch 13/400 Loss: 12.162493228912354\n",
      "Epoch 14/400 Loss: 12.994392395019531\n",
      "Epoch 15/400 Loss: 13.633917808532715\n",
      "Epoch 16/400 Loss: 14.130440711975098\n",
      "Epoch 17/400 Loss: 14.515892028808594\n",
      "Epoch 18/400 Loss: 14.818449020385742\n",
      "Epoch 19/400 Loss: 15.053760051727295\n",
      "Epoch 20/400 Loss: 15.238939762115479\n",
      "Epoch 21/400 Loss: 15.382769107818604\n",
      "Epoch 22/400 Loss: 15.493432521820068\n",
      "Epoch 23/400 Loss: 15.578864574432373\n",
      "Epoch 24/400 Loss: 15.643084526062012\n",
      "Epoch 25/400 Loss: 15.690220355987549\n",
      "Epoch 26/400 Loss: 15.723490238189697\n",
      "Epoch 27/400 Loss: 15.745362758636475\n",
      "Epoch 28/400 Loss: 15.757847309112549\n",
      "Epoch 29/400 Loss: 15.76264762878418\n",
      "Epoch 30/400 Loss: 15.760947704315186\n",
      "Epoch 31/400 Loss: 15.753892421722412\n",
      "Epoch 32/400 Loss: 15.742354393005371\n",
      "Epoch 33/400 Loss: 15.726949214935303\n",
      "Epoch 34/400 Loss: 15.708439826965332\n",
      "Epoch 35/400 Loss: 15.68710470199585\n",
      "Epoch 36/400 Loss: 15.663572788238525\n",
      "Epoch 37/400 Loss: 15.637773990631104\n",
      "Epoch 38/400 Loss: 15.610274314880371\n"
     ]
    }
   ],
   "source": [
    "n_epoch = 200\n",
    "lr = 0.001\n",
    "\n",
    "print('training f')\n",
    "gaussian_transport_dataloader = DataLoader(gaussian_transport_dataset, batch_size=250, shuffle=True)\n",
    "PICNNtrain(model_init_f, gaussian_transport_dataloader, init_z_f, lr=lr, epochs=2*n_epoch)\n",
    "#PICNNtrain(model_init_f, gaussian_transport_dataloader, lr=0.0001, epochs=1, init_z = lambda x: x)\n",
    "\n",
    "print('training g')\n",
    "reversed_gaussian_dataset = MyDataset(gaussian_dataset.Y, gaussian_dataset.C, gaussian_dataset.X)\n",
    "gaussian_transport_dataset_reversed = get_gaussian_transport_dataset(reversed_gaussian_dataset)\n",
    "gaussian_transport_dataloader_reversed = DataLoader(gaussian_transport_dataset_reversed, batch_size=250, shuffle=True)\n",
    "#PICNNtrain(model_init_g, gaussian_transport_dataloader_reversed, lr=0.0001, epochs=25, init_z = lambda x: (1/2) * torch.norm(-x, dim=-1, keepdim=True)**2)\n",
    "PICNNtrain(model_init_g, gaussian_transport_dataloader_reversed, init_z_g, lr=lr, epochs=n_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict_init_f = model_init_f.state_dict()\n",
    "state_dict_init_g = model_init_g.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Dorseuil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('training f')\n",
    "# gaussian_transport_dataloader = DataLoader(gaussian_transport_dataset, batch_size=250, shuffle=True)\n",
    "# train_wasserstein(model_init_f, gaussian_transport_dataloader, lr=0.1, epochs=10, init_z = lambda x: (1/2) * torch.norm(x, dim=-1, keepdim=True)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X, Y, C = gaussian_dataset.X, gaussian_dataset.Y, gaussian_dataset.C\n",
    "# #Calcul de la dérivée du PICNN\n",
    "\n",
    "# for test in range(20):\n",
    "#     x_i = X[test, :, :]\n",
    "#     y_i = Y[test, :, :]\n",
    "#     c_i = C[test, :, :]\n",
    "\n",
    "#     locs = c_i[:,0]\n",
    "#     #print(locs)\n",
    "\n",
    "#     scales = c_i[:,1]\n",
    "#     #print(scales)  \n",
    "\n",
    "\n",
    "#     y_i.requires_grad_(True)\n",
    "#     x_i.requires_grad_(True)\n",
    "#     #c_i.requires_grad_(True)    \n",
    "\n",
    "#     output_model_f = model_init_f(x_i, c_i)\n",
    "#     grad_model_f = torch.autograd.grad(outputs=output_model_f, inputs=x_i, grad_outputs=torch.ones_like(output_model_f), create_graph=True)[0].detach().numpy()\n",
    "\n",
    "#     plt.hist(X[test, :, 0],  bins=15, label = 'X', density = True)\n",
    "#     plt.hist(Y[test, :, 0],  bins=15, label = 'Y', density = True)\n",
    "#     plt.hist(grad_model_f[:, 0],  bins=15, label = 'grad_model', density = True, alpha = 0.5)\n",
    "#     # plt.hist(X_pred,  bins=15, label = 'X_pred', density = True, alpha = 0.5)\n",
    "#     interval_x = np.linspace(-3, 3, 300)\n",
    "#     interval_y = np.linspace(-3*scales[0] + locs[0], 3*scales[0] + locs[0], 300)\n",
    "\n",
    "#     plt.plot(interval_x, stats.norm.pdf(interval_x, loc=0, scale=1), label = 'X_distrib', color = 'blue')\n",
    "#     plt.plot(interval_y, stats.norm.pdf(interval_y, loc = locs[0], scale = scales[0]), label = 'Y_distrib', color = 'orange')\n",
    "\n",
    "#     plt.legend()\n",
    "#     plt.show()\n",
    "\n",
    "\n",
    "#     output_model_g = model_init_g(y_i, c_i)\n",
    "#     grad_model_g = torch.autograd.grad(outputs=output_model_g, inputs=y_i, grad_outputs=torch.ones_like(output_model_g), create_graph=True)[0].detach().numpy()\n",
    "#     plt.hist(X[test, :, 0],  bins=15, label = 'X', density = True, color = 'red')\n",
    "#     #plt.hist(Y[test, :, 0],  bins=15, label = 'Y', density = True, color = 'blue')\n",
    "#     plt.hist(grad_model_g[:, 0],  bins=15, label = 'grad_model', density = True, alpha = 0.5)\n",
    "#     # plt.hist(X_pred,  bins=15, label = 'X_pred', density = True, alpha = 0.5)\n",
    "#     interval_x = np.linspace(-3, 3, 300)\n",
    "#     interval_y = np.linspace(-3*scales[0] + locs[0], 3*scales[0] + locs[0], 300)\n",
    "\n",
    "#     plt.plot(interval_x, stats.norm.pdf(interval_x, loc=0, scale=1), label = 'X_distrib', color = 'blue')\n",
    "#     #plt.plot(interval_y, stats.norm.pdf(interval_y, loc = locs[0], scale = scales[0]), label = 'Y_distrib', color = 'orange')\n",
    "\n",
    "#     plt.legend()\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __Makkuva__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# state_dict_init_f = torch.load('trained_models/training19/models/model_f_0.pth')\n",
    "# state_dict_init_g = torch.load('trained_models/training19/models/model_g_0.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ICNNf = ICNNet(layer_sizes = layer_sizes, context_layer_sizes=context_layer_sizes, init_bunne = 'TR')\n",
    "ICNNg = ICNNet(layer_sizes = layer_sizes, context_layer_sizes=context_layer_sizes, init_bunne = 'TR')\n",
    "\n",
    "# Load the state dictionary into ICNNf and ICNNg\n",
    "ICNNf.load_state_dict(state_dict_init_f)\n",
    "ICNNg.load_state_dict(state_dict_init_g)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_points = 2000\n",
    "test = 21\n",
    "\n",
    "filepath_pth_f = 'trained_models/training19/models/model_f_'\n",
    "filepath_pth_g = 'trained_models/training19/models/model_g_'\n",
    "\n",
    "filepath_plt_f = 'trained_models/training19/plots/model_f_'\n",
    "filepath_plt_g = 'trained_models/training19/plots/model_g_'\n",
    "\n",
    "import os\n",
    "os.makedirs(filepath_pth_f, exist_ok=True)\n",
    "os.makedirs(filepath_pth_g, exist_ok=True)\n",
    "\n",
    "os.makedirs(filepath_plt_f, exist_ok=True)\n",
    "os.makedirs(filepath_plt_g, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_pth_f = filepath_pth_f + str(0) + '.pth'\n",
    "filename_pth_g = filepath_pth_g + str(0) + '.pth'\n",
    "torch.save(ICNNf.state_dict(), filename_pth_f)\n",
    "torch.save(ICNNg.state_dict(), filename_pth_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_plt_f = filepath_plt_f + str(0) + '.png'\n",
    "filename_plt_g = filepath_plt_g + str(0) + '.png'\n",
    "plot_transport(dataset, test, ICNNf, ICNNg, init_z_f = init_z_f, init_z_g = init_z_g, filename_f = filename_plt_f, filename_g = filename_plt_g, n_points=n_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=501, shuffle=True)\n",
    "\n",
    "loss_f = list()\n",
    "loss_g = list()\n",
    "\n",
    "prev_param_f = [param.clone().detach() for param in ICNNf.parameters()]\n",
    "prev_param_g = [param.clone().detach() for param in ICNNg.parameters()]\n",
    "\n",
    "for epoch in range(1, 101) :\n",
    "    print('epoch :', epoch)\n",
    "    mean_loss_f, mean_loss_g, prev_param_f, prev_param_g = train_makkuva_epoch(ICNNf=ICNNf, ICNNg=ICNNg, prev_param_f=prev_param_f, prev_param_g=prev_param_g, dataloader = dataloader, init_z_f = init_z_f, init_z_g = init_z_g, lr=0.0005, train_freq_g=10, train_freq_f=1, regularize_f = True, regularize_g = True, lambda_proximal=0.0001)\n",
    "    #mean_loss_f, mean_loss_g = train_makkuva_epoch(ICNNf, ICNNg, None, None, dataloader, init_z_f = lambda x: (1/2) * torch.norm(x, dim=-1, keepdim=True)**2, init_z_g = lambda x: (1/2) * torch.norm(-x, dim=-1, keepdim=True)**2, lr=0.0001, train_freq_g=10, train_freq_f=1, gaussian_transport=False)\n",
    "\n",
    "    loss_f.append(mean_loss_f)\n",
    "    loss_g.append(mean_loss_g)\n",
    "\n",
    "    filename_plt_f = filepath_plt_f + str(epoch) + '.png'\n",
    "    filename_plt_g = filepath_plt_g + str(epoch) + '.png'\n",
    "    plot_transport(dataset, test, ICNNf, ICNNg, init_z_f=init_z_f, init_z_g=init_z_g, filename_f = filename_plt_f, filename_g = filename_plt_g, n_points=n_points)  \n",
    "\n",
    "    filename_pth_f = filepath_pth_f + str(epoch) + '.pth'\n",
    "    filename_pth_g = filepath_pth_g + str(epoch) + '.pth'\n",
    "    torch.save(ICNNf.state_dict(), filename_pth_f)\n",
    "    torch.save(ICNNg.state_dict(), filename_pth_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_test = [12]\n",
    "for epoch in range(1, 101) :\n",
    "    epoch = epoch\n",
    "    print('epoch :', epoch)\n",
    "\n",
    "    filename_pth_f = filepath_pth_f + str(epoch) + '.pth'\n",
    "    filename_pth_g = filepath_pth_g + str(epoch) + '.pth'\n",
    "\n",
    "    state_dict_init_f = torch.load(filename_pth_f)\n",
    "    state_dict_init_g = torch.load(filename_pth_f)\n",
    "\n",
    "    ICNNf.load_state_dict(state_dict_init_f)\n",
    "    ICNNg.load_state_dict(state_dict_init_g)\n",
    "\n",
    "    for test in l_test :\n",
    "        filename_plt_f = filepath_plt_f + 'test_' + str(test) + '_'  +str(epoch) + '.png'\n",
    "        filename_plt_g = filepath_plt_g + 'test_' + str(test) + '_' + str(epoch) + '.png'\n",
    "        plot_transport(dataset, test, ICNNf, ICNNg, init_z_f=init_z_f, init_z_g=init_z_g, filename_f = filename_plt_f, filename_g = filename_plt_g, n_points=n_points)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for ele in loss_f:\n",
    "#     print(ele)\n",
    "\n",
    "# print('stop')\n",
    "\n",
    "# for ele in loss_g:\n",
    "#     print(ele)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
