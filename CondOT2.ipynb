{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import scipy.stats as stats\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import optim\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from icnnet import ICNNet\n",
    "from mydataset import MyDataset, get_gaussian_dataset, get_gaussian_transport_dataset\n",
    "from toy_data_dataloader_gaussian import generate_gaussian_dataset, get_dataset, generate_dataset, generate_traj\n",
    "from train_picnn import PICNNtrain\n",
    "from train_wasserstein import train_wasserstein\n",
    "from train_makkuva import train_makkuva, train_makkuva_epoch\n",
    "from visualization import plot_transport\n",
    "from gaussian_transport import get_gaussian_transport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __Generate dataset__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.0158,  0.0075],\n",
      "         [ 0.0124,  0.0023],\n",
      "         [ 0.0056,  0.0156],\n",
      "         ...,\n",
      "         [ 0.0218,  0.0102],\n",
      "         [ 0.0068,  0.0029],\n",
      "         [ 0.0469,  0.0016]],\n",
      "\n",
      "        [[ 0.0513,  0.0102],\n",
      "         [ 0.0186,  0.0070],\n",
      "         [ 0.0148,  0.0169],\n",
      "         ...,\n",
      "         [ 0.0231,  0.0105],\n",
      "         [ 0.0204,  0.0102],\n",
      "         [ 0.0637,  0.0131]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.1073,  0.0142],\n",
      "         [-0.0540,  0.0111],\n",
      "         [ 0.0831, -0.0050],\n",
      "         ...,\n",
      "         [-0.0478,  0.0820],\n",
      "         [ 0.0802,  0.0857],\n",
      "         [ 0.2037,  0.0414]],\n",
      "\n",
      "        [[ 0.0898, -0.0050],\n",
      "         [-0.0602,  0.0042],\n",
      "         [ 0.0680, -0.0291],\n",
      "         ...,\n",
      "         [-0.0488,  0.0803],\n",
      "         [ 0.0736,  0.0634],\n",
      "         [ 0.2004,  0.0385]],\n",
      "\n",
      "        [[ 0.0937, -0.0014],\n",
      "         [-0.0553,  0.0172],\n",
      "         [ 0.0699, -0.0167],\n",
      "         ...,\n",
      "         [-0.0482,  0.0877],\n",
      "         [ 0.0851,  0.0648],\n",
      "         [ 0.2029,  0.0479]]], dtype=torch.float64)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "array must not contain infs or NaNs",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[59], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m#dataset = generate_dataset(d=2, r=500, N=50)\u001b[39;00m\n\u001b[1;32m      5\u001b[0m gaussian_dataset \u001b[38;5;241m=\u001b[39m get_gaussian_dataset(dataset)\n\u001b[0;32m----> 6\u001b[0m gaussian_transport_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mget_gaussian_transport_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgaussian_dataset\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/CondOT/CondOT-1/mydataset.py:61\u001b[0m, in \u001b[0;36mget_gaussian_transport_dataset\u001b[0;34m(gaussian_dataset)\u001b[0m\n\u001b[1;32m     58\u001b[0m     mean_y \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmean(y_i, dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     59\u001b[0m     cov_matrix_y \u001b[38;5;241m=\u001b[39m ((y_i\u001b[38;5;241m-\u001b[39mmean_y)\u001b[38;5;241m.\u001b[39mT \u001b[38;5;241m@\u001b[39m (y_i \u001b[38;5;241m-\u001b[39m mean_y)) \u001b[38;5;241m/\u001b[39m (y_i\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 61\u001b[0m     l_transported\u001b[38;5;241m.\u001b[39mappend(\u001b[43mget_gaussian_transport\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcov_matrix_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcov_matrix_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmean_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmean_y\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;66;03m# for j in range(x_i.shape[0]) :\u001b[39;00m\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;66;03m#     #print(x_i[j].shape, A.shape, w.shape)\u001b[39;00m\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;66;03m#     Y_transport[i,j] = gaussian_transport(x_i[j], A, w)\u001b[39;00m\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;66;03m#     #print(Y_transport[i,j].shape)\u001b[39;00m\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;66;03m#     #print(x_i[j], A, w, Y_transport[i,j])\u001b[39;00m\n\u001b[1;32m     69\u001b[0m Y_transport \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack(l_transported, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/CondOT/CondOT-1/gaussian_transport.py:61\u001b[0m, in \u001b[0;36mget_gaussian_transport\u001b[0;34m(u, cov1, cov2, m1, m2)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_gaussian_transport\u001b[39m(u, cov1, cov2, m1, m2) :\n\u001b[0;32m---> 61\u001b[0m     A \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_A\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcov1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcov2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m     w \u001b[38;5;241m=\u001b[39m compute_w(m1, m2, A)\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m(gaussian_transport(u, A, w))\n",
      "File \u001b[0;32m~/Desktop/CondOT/CondOT-1/gaussian_transport.py:13\u001b[0m, in \u001b[0;36mcompute_A\u001b[0;34m(cov1, cov2)\u001b[0m\n\u001b[1;32m     10\u001b[0m cov1_moins12 \u001b[38;5;241m=\u001b[39m scipy\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mfractional_matrix_power(cov1, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.5\u001b[39m)\n\u001b[1;32m     11\u001b[0m cov1_12 \u001b[38;5;241m=\u001b[39m scipy\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39msqrtm(cov1)\n\u001b[0;32m---> 13\u001b[0m A \u001b[38;5;241m=\u001b[39m \u001b[43mscipy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqrtm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcov1_moins12\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mscipy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqrtm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcov1_12\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcov2\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcov1_12\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcov1_moins12\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m A \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mreal(A)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m(A)\n",
      "File \u001b[0;32m~/Desktop/CondOT/CondOT-1/python_env_condot/lib64/python3.9/site-packages/scipy/linalg/_matfuncs_sqrtm.py:167\u001b[0m, in \u001b[0;36msqrtm\u001b[0;34m(A, disp, blocksize)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;124;03mMatrix square root.\u001b[39;00m\n\u001b[1;32m    120\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    164\u001b[0m \n\u001b[1;32m    165\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    166\u001b[0m byte_size \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(A)\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mitemsize\n\u001b[0;32m--> 167\u001b[0m A \u001b[38;5;241m=\u001b[39m \u001b[43m_asarray_validated\u001b[49m\u001b[43m(\u001b[49m\u001b[43mA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_inexact\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(A\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNon-matrix input to matrix function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/CondOT/CondOT-1/python_env_condot/lib64/python3.9/site-packages/scipy/_lib/_util.py:306\u001b[0m, in \u001b[0;36m_asarray_validated\u001b[0;34m(a, check_finite, sparse_ok, objects_ok, mask_ok, as_inexact)\u001b[0m\n\u001b[1;32m    304\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmasked arrays are not supported\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    305\u001b[0m toarray \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray_chkfinite \u001b[38;5;28;01mif\u001b[39;00m check_finite \u001b[38;5;28;01melse\u001b[39;00m np\u001b[38;5;241m.\u001b[39masarray\n\u001b[0;32m--> 306\u001b[0m a \u001b[38;5;241m=\u001b[39m \u001b[43mtoarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m objects_ok:\n\u001b[1;32m    308\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m a\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;129;01mis\u001b[39;00m np\u001b[38;5;241m.\u001b[39mdtype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mO\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "File \u001b[0;32m~/Desktop/CondOT/CondOT-1/python_env_condot/lib64/python3.9/site-packages/numpy/lib/function_base.py:630\u001b[0m, in \u001b[0;36masarray_chkfinite\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    628\u001b[0m a \u001b[38;5;241m=\u001b[39m asarray(a, dtype\u001b[38;5;241m=\u001b[39mdtype, order\u001b[38;5;241m=\u001b[39morder)\n\u001b[1;32m    629\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m a\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mchar \u001b[38;5;129;01min\u001b[39;00m typecodes[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAllFloat\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misfinite(a)\u001b[38;5;241m.\u001b[39mall():\n\u001b[0;32m--> 630\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    631\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray must not contain infs or NaNs\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m a\n",
      "\u001b[0;31mValueError\u001b[0m: array must not contain infs or NaNs"
     ]
    }
   ],
   "source": [
    "#dataset = get_dataset(d=2, r=100, N=500) #valou\n",
    "#dataset = generate_gaussian_dataset(d=2, r=400, N=10000) #thomas\n",
    "#dataset = generate_traj(d = 2, r = 100, N=50)\n",
    "dataset = generate_dataset(d=2, r=500, N=50)\n",
    "gaussian_dataset = get_gaussian_dataset(dataset)\n",
    "gaussian_transport_dataset = get_gaussian_transport_dataset(gaussian_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean(batch):\n",
    "    means = torch.mean(batch, dim=1)\n",
    "    average_mean = torch.mean(means, dim=0)\n",
    "    return(average_mean)\n",
    "\n",
    "def get_covariance(batch):\n",
    "    n = batch.size(1) - 1\n",
    "    mean = torch.mean(batch, dim=1, keepdim=True)\n",
    "    batch = batch - mean  # Centering the data\n",
    "    cov = torch.matmul(batch.transpose(1, 2), batch) / n\n",
    "    return(torch.mean(cov, dim=0))\n",
    "\n",
    "mean1 = get_mean(dataset.X)\n",
    "cov1 = get_covariance(dataset.X)\n",
    "mean2 = get_mean(dataset.Y)\n",
    "cov2 = get_covariance(dataset.Y)\n",
    "\n",
    "def init_z_f(x):\n",
    "    #return(x)\n",
    "    #return x\n",
    "    #return (1/2) * torch.norm(x, dim=-1, keepdim=True)**2\n",
    "    return(get_gaussian_transport(u=x, cov1 = cov1, cov2 = cov2, m1=mean1, m2=mean2))\n",
    "\n",
    "def init_z_g(x) :\n",
    "    #return(x)\n",
    "    #return x\n",
    "    #return (1/2) * torch.norm(x, dim=-1, keepdim=True)**2\n",
    "    return(get_gaussian_transport(u=x, cov1 = cov2, cov2 = cov1, m1=mean2, m2=mean1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __Initialization__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __PICNN training__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 2\n",
    "layer_sizes = [input_size,64, 64, 64, 1]\n",
    "n_layers = len(layer_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "# def get_embedding(C, c):\n",
    "#     scalar_product = torch.matmul(c.float(), C.t().float())\n",
    "#     embedding = F.softmax(scalar_product, dim=1)\n",
    "#     return(embedding)\n",
    "\n",
    "context_layer_sizes = [12] + [64] * (n_layers-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_init_f = ICNNet(layer_sizes = layer_sizes, context_layer_sizes=context_layer_sizes, init_bunne = 'TR')\n",
    "model_init_g = ICNNet(layer_sizes = layer_sizes, context_layer_sizes=context_layer_sizes, init_bunne = 'TR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training f\n",
      "Epoch 1/200 Loss: 261.4753112792969\n",
      "Epoch 2/200 Loss: 232.5139617919922\n",
      "Epoch 3/200 Loss: 200.73245239257812\n",
      "Epoch 4/200 Loss: 167.34132385253906\n",
      "Epoch 5/200 Loss: 135.1083526611328\n",
      "Epoch 6/200 Loss: 109.26573944091797\n",
      "Epoch 7/200 Loss: 98.717529296875\n",
      "Epoch 8/200 Loss: 112.18524169921875\n",
      "Epoch 9/200 Loss: 131.29757690429688\n",
      "Epoch 10/200 Loss: 132.34042358398438\n",
      "Epoch 11/200 Loss: 120.81974029541016\n",
      "Epoch 12/200 Loss: 108.17781829833984\n",
      "Epoch 13/200 Loss: 100.48158264160156\n",
      "Epoch 14/200 Loss: 98.4637680053711\n",
      "Epoch 15/200 Loss: 100.23783874511719\n",
      "Epoch 16/200 Loss: 103.52745819091797\n",
      "Epoch 17/200 Loss: 106.62254333496094\n",
      "Epoch 18/200 Loss: 108.57073974609375\n",
      "Epoch 19/200 Loss: 109.026123046875\n",
      "Epoch 20/200 Loss: 108.06221771240234\n",
      "Epoch 21/200 Loss: 106.02684020996094\n",
      "Epoch 22/200 Loss: 103.43756866455078\n",
      "Epoch 23/200 Loss: 100.8939208984375\n",
      "Epoch 24/200 Loss: 98.97386169433594\n",
      "Epoch 25/200 Loss: 98.09410095214844\n",
      "Epoch 26/200 Loss: 98.3560562133789\n",
      "Epoch 27/200 Loss: 99.45410919189453\n",
      "Epoch 28/200 Loss: 100.75196838378906\n",
      "Epoch 29/200 Loss: 101.56661987304688\n",
      "Epoch 30/200 Loss: 101.51679992675781\n",
      "Epoch 31/200 Loss: 100.68061828613281\n",
      "Epoch 32/200 Loss: 99.48396301269531\n",
      "Epoch 33/200 Loss: 98.4178237915039\n",
      "Epoch 34/200 Loss: 97.80303955078125\n",
      "Epoch 35/200 Loss: 97.70841979980469\n",
      "Epoch 36/200 Loss: 97.99568176269531\n",
      "Epoch 37/200 Loss: 98.42994689941406\n",
      "Epoch 38/200 Loss: 98.78563690185547\n",
      "Epoch 39/200 Loss: 98.9151382446289\n",
      "Epoch 40/200 Loss: 98.77533721923828\n",
      "Epoch 41/200 Loss: 98.41999053955078\n",
      "Epoch 42/200 Loss: 97.9686279296875\n",
      "Epoch 43/200 Loss: 97.5611572265625\n",
      "Epoch 44/200 Loss: 97.30879211425781\n",
      "Epoch 45/200 Loss: 97.25411987304688\n",
      "Epoch 46/200 Loss: 97.35645294189453\n",
      "Epoch 47/200 Loss: 97.51299285888672\n",
      "Epoch 48/200 Loss: 97.60945892333984\n",
      "Epoch 49/200 Loss: 97.57396697998047\n",
      "Epoch 50/200 Loss: 97.40892791748047\n",
      "Epoch 51/200 Loss: 97.17801666259766\n",
      "Epoch 52/200 Loss: 96.96441650390625\n",
      "Epoch 53/200 Loss: 96.8276596069336\n",
      "Epoch 54/200 Loss: 96.78140258789062\n",
      "Epoch 55/200 Loss: 96.796142578125\n",
      "Epoch 56/200 Loss: 96.82215881347656\n",
      "Epoch 57/200 Loss: 96.81437683105469\n",
      "Epoch 58/200 Loss: 96.75041961669922\n",
      "Epoch 59/200 Loss: 96.63591766357422\n",
      "Epoch 60/200 Loss: 96.49732208251953\n",
      "Epoch 61/200 Loss: 96.36805725097656\n",
      "Epoch 62/200 Loss: 96.27198028564453\n",
      "Epoch 63/200 Loss: 96.21369934082031\n",
      "Epoch 64/200 Loss: 96.1778793334961\n",
      "Epoch 65/200 Loss: 96.13902282714844\n",
      "Epoch 66/200 Loss: 96.07630157470703\n",
      "Epoch 67/200 Loss: 95.98361206054688\n",
      "Epoch 68/200 Loss: 95.87095642089844\n",
      "Epoch 69/200 Loss: 95.75621032714844\n",
      "Epoch 70/200 Loss: 95.65406036376953\n",
      "Epoch 71/200 Loss: 95.5683364868164\n",
      "Epoch 72/200 Loss: 95.49224090576172\n",
      "Epoch 73/200 Loss: 95.41410064697266\n",
      "Epoch 74/200 Loss: 95.3223876953125\n",
      "Epoch 75/200 Loss: 95.21308135986328\n",
      "Epoch 76/200 Loss: 95.09102630615234\n",
      "Epoch 77/200 Loss: 94.9640121459961\n",
      "Epoch 78/200 Loss: 94.84078216552734\n",
      "Epoch 79/200 Loss: 94.72283172607422\n",
      "Epoch 80/200 Loss: 94.60498046875\n",
      "Epoch 81/200 Loss: 94.47833251953125\n",
      "Epoch 82/200 Loss: 94.33673858642578\n",
      "Epoch 83/200 Loss: 94.18051147460938\n",
      "Epoch 84/200 Loss: 94.01519775390625\n",
      "Epoch 85/200 Loss: 93.8466796875\n",
      "Epoch 86/200 Loss: 93.67597961425781\n",
      "Epoch 87/200 Loss: 93.49884796142578\n",
      "Epoch 88/200 Loss: 93.30574798583984\n",
      "Epoch 89/200 Loss: 93.09330749511719\n",
      "Epoch 90/200 Loss: 92.86447143554688\n",
      "Epoch 91/200 Loss: 92.62439727783203\n",
      "Epoch 92/200 Loss: 92.37309265136719\n",
      "Epoch 93/200 Loss: 92.10269165039062\n",
      "Epoch 94/200 Loss: 91.80461120605469\n",
      "Epoch 95/200 Loss: 91.4773178100586\n",
      "Epoch 96/200 Loss: 91.12389373779297\n",
      "Epoch 97/200 Loss: 90.74504089355469\n",
      "Epoch 98/200 Loss: 90.33213806152344\n",
      "Epoch 99/200 Loss: 89.87531280517578\n",
      "Epoch 100/200 Loss: 89.3709487915039\n",
      "Epoch 101/200 Loss: 88.81842041015625\n",
      "Epoch 102/200 Loss: 88.20832061767578\n",
      "Epoch 103/200 Loss: 87.52522277832031\n",
      "Epoch 104/200 Loss: 86.75923156738281\n",
      "Epoch 105/200 Loss: 85.90440368652344\n",
      "Epoch 106/200 Loss: 84.94542694091797\n",
      "Epoch 107/200 Loss: 83.86228942871094\n",
      "Epoch 108/200 Loss: 82.6353530883789\n",
      "Epoch 109/200 Loss: 81.24449920654297\n",
      "Epoch 110/200 Loss: 79.66217803955078\n",
      "Epoch 111/200 Loss: 77.86099243164062\n",
      "Epoch 112/200 Loss: 75.81498718261719\n",
      "Epoch 113/200 Loss: 73.50811767578125\n",
      "Epoch 114/200 Loss: 70.93450927734375\n",
      "Epoch 115/200 Loss: 68.12016296386719\n",
      "Epoch 116/200 Loss: 65.15400695800781\n",
      "Epoch 117/200 Loss: 62.39888000488281\n",
      "Epoch 118/200 Loss: 60.513671875\n",
      "Epoch 119/200 Loss: 59.7230339050293\n",
      "Epoch 120/200 Loss: 59.90394973754883\n",
      "Epoch 121/200 Loss: 60.784149169921875\n",
      "Epoch 122/200 Loss: 61.59281921386719\n",
      "Epoch 123/200 Loss: 61.65277099609375\n",
      "Epoch 124/200 Loss: 60.7453498840332\n",
      "Epoch 125/200 Loss: 59.205650329589844\n",
      "Epoch 126/200 Loss: 57.47909927368164\n",
      "Epoch 127/200 Loss: 55.95867156982422\n",
      "Epoch 128/200 Loss: 54.78813171386719\n",
      "Epoch 129/200 Loss: 53.99085998535156\n",
      "Epoch 130/200 Loss: 53.45669937133789\n",
      "Epoch 131/200 Loss: 53.07685852050781\n",
      "Epoch 132/200 Loss: 52.74256134033203\n",
      "Epoch 133/200 Loss: 52.36966323852539\n",
      "Epoch 134/200 Loss: 51.92485427856445\n",
      "Epoch 135/200 Loss: 51.38885498046875\n",
      "Epoch 136/200 Loss: 50.785640716552734\n",
      "Epoch 137/200 Loss: 50.1497802734375\n",
      "Epoch 138/200 Loss: 49.52959060668945\n",
      "Epoch 139/200 Loss: 48.9781608581543\n",
      "Epoch 140/200 Loss: 48.524898529052734\n",
      "Epoch 141/200 Loss: 48.18967819213867\n",
      "Epoch 142/200 Loss: 47.95800018310547\n",
      "Epoch 143/200 Loss: 47.79412841796875\n",
      "Epoch 144/200 Loss: 47.65269470214844\n",
      "Epoch 145/200 Loss: 47.48810958862305\n",
      "Epoch 146/200 Loss: 47.27608108520508\n",
      "Epoch 147/200 Loss: 47.01686096191406\n",
      "Epoch 148/200 Loss: 46.73565673828125\n",
      "Epoch 149/200 Loss: 46.46482849121094\n",
      "Epoch 150/200 Loss: 46.235633850097656\n",
      "Epoch 151/200 Loss: 46.05699157714844\n",
      "Epoch 152/200 Loss: 45.92374038696289\n",
      "Epoch 153/200 Loss: 45.82566452026367\n",
      "Epoch 154/200 Loss: 45.74589157104492\n",
      "Epoch 155/200 Loss: 45.669979095458984\n",
      "Epoch 156/200 Loss: 45.587623596191406\n",
      "Epoch 157/200 Loss: 45.49687957763672\n",
      "Epoch 158/200 Loss: 45.400203704833984\n",
      "Epoch 159/200 Loss: 45.305660247802734\n",
      "Epoch 160/200 Loss: 45.221038818359375\n",
      "Epoch 161/200 Loss: 45.15229034423828\n",
      "Epoch 162/200 Loss: 45.101219177246094\n",
      "Epoch 163/200 Loss: 45.06467056274414\n",
      "Epoch 164/200 Loss: 45.036380767822266\n",
      "Epoch 165/200 Loss: 45.00851058959961\n",
      "Epoch 166/200 Loss: 44.97726058959961\n",
      "Epoch 167/200 Loss: 44.940731048583984\n",
      "Epoch 168/200 Loss: 44.90153503417969\n",
      "Epoch 169/200 Loss: 44.86325454711914\n",
      "Epoch 170/200 Loss: 44.83055877685547\n",
      "Epoch 171/200 Loss: 44.80501174926758\n",
      "Epoch 172/200 Loss: 44.78709411621094\n",
      "Epoch 173/200 Loss: 44.77428436279297\n",
      "Epoch 174/200 Loss: 44.764015197753906\n",
      "Epoch 175/200 Loss: 44.7535285949707\n",
      "Epoch 176/200 Loss: 44.74153137207031\n",
      "Epoch 177/200 Loss: 44.72792053222656\n",
      "Epoch 178/200 Loss: 44.71408462524414\n",
      "Epoch 179/200 Loss: 44.70174026489258\n",
      "Epoch 180/200 Loss: 44.69224548339844\n",
      "Epoch 181/200 Loss: 44.685909271240234\n",
      "Epoch 182/200 Loss: 44.6822395324707\n",
      "Epoch 183/200 Loss: 44.6798210144043\n",
      "Epoch 184/200 Loss: 44.67729187011719\n",
      "Epoch 185/200 Loss: 44.67380905151367\n",
      "Epoch 186/200 Loss: 44.66946029663086\n",
      "Epoch 187/200 Loss: 44.66472625732422\n",
      "Epoch 188/200 Loss: 44.66025924682617\n",
      "Epoch 189/200 Loss: 44.65665054321289\n",
      "Epoch 190/200 Loss: 44.65407943725586\n",
      "Epoch 191/200 Loss: 44.65227508544922\n",
      "Epoch 192/200 Loss: 44.650718688964844\n",
      "Epoch 193/200 Loss: 44.64891815185547\n",
      "Epoch 194/200 Loss: 44.64656448364258\n",
      "Epoch 195/200 Loss: 44.6436653137207\n",
      "Epoch 196/200 Loss: 44.64046859741211\n",
      "Epoch 197/200 Loss: 44.637271881103516\n",
      "Epoch 198/200 Loss: 44.63432312011719\n",
      "Epoch 199/200 Loss: 44.631710052490234\n",
      "Epoch 200/200 Loss: 44.62929916381836\n",
      "training g\n",
      "Epoch 1/100 Loss: 134.0359344482422\n",
      "Epoch 2/100 Loss: 73.99385833740234\n",
      "Epoch 3/100 Loss: 39.34400939941406\n",
      "Epoch 4/100 Loss: 20.28946304321289\n",
      "Epoch 5/100 Loss: 10.243468284606934\n",
      "Epoch 6/100 Loss: 5.189216136932373\n",
      "Epoch 7/100 Loss: 2.8054425716400146\n",
      "Epoch 8/100 Loss: 1.8145431280136108\n",
      "Epoch 9/100 Loss: 1.5279440879821777\n",
      "Epoch 10/100 Loss: 1.5788853168487549\n",
      "Epoch 11/100 Loss: 1.7774015665054321\n",
      "Epoch 12/100 Loss: 2.026322841644287\n",
      "Epoch 13/100 Loss: 2.2673635482788086\n",
      "Epoch 14/100 Loss: 2.477144241333008\n",
      "Epoch 15/100 Loss: 2.6489009857177734\n",
      "Epoch 16/100 Loss: 2.7873306274414062\n",
      "Epoch 17/100 Loss: 2.8947272300720215\n",
      "Epoch 18/100 Loss: 2.974367141723633\n",
      "Epoch 19/100 Loss: 3.030745506286621\n",
      "Epoch 20/100 Loss: 3.066782236099243\n",
      "Epoch 21/100 Loss: 3.0856199264526367\n",
      "Epoch 22/100 Loss: 3.090071201324463\n",
      "Epoch 23/100 Loss: 3.0826618671417236\n",
      "Epoch 24/100 Loss: 3.065718650817871\n",
      "Epoch 25/100 Loss: 3.041130542755127\n",
      "Epoch 26/100 Loss: 3.0104637145996094\n",
      "Epoch 27/100 Loss: 2.975165605545044\n",
      "Epoch 28/100 Loss: 2.936243772506714\n",
      "Epoch 29/100 Loss: 2.8945305347442627\n",
      "Epoch 30/100 Loss: 2.8505916595458984\n",
      "Epoch 31/100 Loss: 2.8055975437164307\n",
      "Epoch 32/100 Loss: 2.7596631050109863\n",
      "Epoch 33/100 Loss: 2.7132339477539062\n",
      "Epoch 34/100 Loss: 2.666811227798462\n",
      "Epoch 35/100 Loss: 2.6206796169281006\n",
      "Epoch 36/100 Loss: 2.575122594833374\n",
      "Epoch 37/100 Loss: 2.530363082885742\n",
      "Epoch 38/100 Loss: 2.4866061210632324\n",
      "Epoch 39/100 Loss: 2.4439570903778076\n",
      "Epoch 40/100 Loss: 2.4026472568511963\n",
      "Epoch 41/100 Loss: 2.3615851402282715\n",
      "Epoch 42/100 Loss: 2.3217527866363525\n",
      "Epoch 43/100 Loss: 2.2831952571868896\n",
      "Epoch 44/100 Loss: 2.2462217807769775\n",
      "Epoch 45/100 Loss: 2.2115256786346436\n",
      "Epoch 46/100 Loss: 2.1793084144592285\n",
      "Epoch 47/100 Loss: 2.1497561931610107\n",
      "Epoch 48/100 Loss: 2.1232547760009766\n",
      "Epoch 49/100 Loss: 2.1000866889953613\n",
      "Epoch 50/100 Loss: 2.0803589820861816\n",
      "Epoch 51/100 Loss: 2.0639727115631104\n",
      "Epoch 52/100 Loss: 2.050478458404541\n",
      "Epoch 53/100 Loss: 2.0390825271606445\n",
      "Epoch 54/100 Loss: 2.028822183609009\n",
      "Epoch 55/100 Loss: 2.0187034606933594\n",
      "Epoch 56/100 Loss: 2.0078091621398926\n",
      "Epoch 57/100 Loss: 1.9953936338424683\n",
      "Epoch 58/100 Loss: 1.980867862701416\n",
      "Epoch 59/100 Loss: 1.9639140367507935\n",
      "Epoch 60/100 Loss: 1.9444804191589355\n",
      "Epoch 61/100 Loss: 1.9230799674987793\n",
      "Epoch 62/100 Loss: 1.900455355644226\n",
      "Epoch 63/100 Loss: 1.8764864206314087\n",
      "Epoch 64/100 Loss: 1.8516106605529785\n",
      "Epoch 65/100 Loss: 1.827151894569397\n",
      "Epoch 66/100 Loss: 1.8027704954147339\n",
      "Epoch 67/100 Loss: 1.7787244319915771\n",
      "Epoch 68/100 Loss: 1.7552233934402466\n",
      "Epoch 69/100 Loss: 1.7323036193847656\n",
      "Epoch 70/100 Loss: 1.7101759910583496\n",
      "Epoch 71/100 Loss: 1.6882202625274658\n",
      "Epoch 72/100 Loss: 1.6663650274276733\n",
      "Epoch 73/100 Loss: 1.6446725130081177\n",
      "Epoch 74/100 Loss: 1.6230716705322266\n",
      "Epoch 75/100 Loss: 1.601847767829895\n",
      "Epoch 76/100 Loss: 1.5809568166732788\n",
      "Epoch 77/100 Loss: 1.560293436050415\n",
      "Epoch 78/100 Loss: 1.5397571325302124\n",
      "Epoch 79/100 Loss: 1.5191065073013306\n",
      "Epoch 80/100 Loss: 1.498072862625122\n",
      "Epoch 81/100 Loss: 1.4765576124191284\n",
      "Epoch 82/100 Loss: 1.4545931816101074\n",
      "Epoch 83/100 Loss: 1.4322999715805054\n",
      "Epoch 84/100 Loss: 1.4097775220870972\n",
      "Epoch 85/100 Loss: 1.3869012594223022\n",
      "Epoch 86/100 Loss: 1.3635408878326416\n",
      "Epoch 87/100 Loss: 1.3393601179122925\n",
      "Epoch 88/100 Loss: 1.314671516418457\n",
      "Epoch 89/100 Loss: 1.2893058061599731\n",
      "Epoch 90/100 Loss: 1.2629512548446655\n",
      "Epoch 91/100 Loss: 1.2354365587234497\n",
      "Epoch 92/100 Loss: 1.2065566778182983\n",
      "Epoch 93/100 Loss: 1.1762646436691284\n",
      "Epoch 94/100 Loss: 1.1444169282913208\n",
      "Epoch 95/100 Loss: 1.1108918190002441\n",
      "Epoch 96/100 Loss: 1.075979471206665\n",
      "Epoch 97/100 Loss: 1.0393908023834229\n",
      "Epoch 98/100 Loss: 1.0012824535369873\n",
      "Epoch 99/100 Loss: 0.9620338082313538\n",
      "Epoch 100/100 Loss: 0.9219768047332764\n"
     ]
    }
   ],
   "source": [
    "n_epoch = 200\n",
    "lr = 0.001\n",
    "\n",
    "print('training f')\n",
    "gaussian_transport_dataloader = DataLoader(gaussian_transport_dataset, batch_size=250, shuffle=True)\n",
    "PICNNtrain(model_init_f, gaussian_transport_dataloader, init_z_f, lr=lr, epochs=n_epoch)\n",
    "#PICNNtrain(model_init_f, gaussian_transport_dataloader, init_z_f, lr=lr, epochs=n_epoch)\n",
    "#PICNNtrain(model_init_f, gaussian_transport_dataloader, lr=0.0001, epochs=1, init_z = lambda x: x)\n",
    "\n",
    "print('training g')\n",
    "reversed_gaussian_dataset = MyDataset(gaussian_dataset.Y, gaussian_dataset.C, gaussian_dataset.X)\n",
    "gaussian_transport_dataset_reversed = get_gaussian_transport_dataset(reversed_gaussian_dataset)\n",
    "gaussian_transport_dataloader_reversed = DataLoader(gaussian_transport_dataset_reversed, batch_size=250, shuffle=True)\n",
    "#PICNNtrain(model_init_g, gaussian_transport_dataloader_reversed, lr=0.0001, epochs=25, init_z = lambda x: (1/2) * torch.norm(-x, dim=-1, keepdim=True)**2)\n",
    "PICNNtrain(model_init_g, gaussian_transport_dataloader_reversed, init_z_g, lr=lr, epochs=int(n_epoch/2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict_init_f = model_init_f.state_dict()\n",
    "state_dict_init_g = model_init_g.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Dorseuil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __Makkuva__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# state_dict_init_f = torch.load('trained_models/training22/models/model_f_0.pth')\n",
    "# state_dict_init_g = torch.load('trained_models/training22/models/model_g_0.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ICNNf = ICNNet(layer_sizes = layer_sizes, context_layer_sizes=context_layer_sizes, init_bunne = 'TR')\n",
    "ICNNg = ICNNet(layer_sizes = layer_sizes, context_layer_sizes=context_layer_sizes, init_bunne = 'TR')\n",
    "\n",
    "# Load the state dictionary into ICNNf and ICNNg\n",
    "ICNNf.load_state_dict(state_dict_init_f)\n",
    "ICNNg.load_state_dict(state_dict_init_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_points = 2000\n",
    "test = 14\n",
    "\n",
    "filepath_pth_f = 'trained_models/training22/models/model_f_'\n",
    "filepath_pth_g = 'trained_models/training22/models/model_g_'\n",
    "\n",
    "filepath_plt_f = 'trained_models/training22/plots/model_f_'\n",
    "filepath_plt_g = 'trained_models/training22/plots/model_g_'\n",
    "\n",
    "import os\n",
    "os.makedirs(filepath_pth_f, exist_ok=True)\n",
    "os.makedirs(filepath_pth_g, exist_ok=True)\n",
    "\n",
    "os.makedirs(filepath_plt_f, exist_ok=True)\n",
    "os.makedirs(filepath_plt_g, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_pth_f = filepath_pth_f + str(0) + '.pth'\n",
    "filename_pth_g = filepath_pth_g + str(0) + '.pth'\n",
    "torch.save(ICNNf.state_dict(), filename_pth_f)\n",
    "torch.save(ICNNg.state_dict(), filename_pth_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "filename_plt_f = filepath_plt_f + str(0) + '.png'\n",
    "filename_plt_g = filepath_plt_g + str(0) + '.png'\n",
    "plot_transport(dataset, test, ICNNf, ICNNg, init_z_f = init_z_f, init_z_g = init_z_g, filename_f = filename_plt_f, filename_g = filename_plt_g, n_points=n_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1\n",
      "4.4833221435546875\n",
      "2.674133539199829\n",
      "8.590400695800781\n",
      "2.7793331146240234\n",
      "1.1766952276229858\n",
      "loss_g: 1.1766952276229858, loss_f: 8.093396186828613\n",
      "epoch : 2\n",
      "5.18220329284668\n",
      "1.373329520225525\n",
      "0.762019157409668\n",
      "2.355783224105835\n",
      "1.8270970582962036\n",
      "loss_g: 1.8270970582962036, loss_f: 10.272769927978516\n",
      "epoch : 3\n",
      "1.380231499671936\n",
      "0.33704113960266113\n",
      "0.35730239748954773\n",
      "0.3855452835559845\n",
      "0.5554842352867126\n",
      "loss_g: 0.5554842352867126, loss_f: 8.232588768005371\n",
      "epoch : 4\n",
      "0.07355661690235138\n",
      "-0.312826931476593\n",
      "-0.45284754037857056\n",
      "-0.5347052812576294\n",
      "-0.622500479221344\n",
      "loss_g: -0.622500479221344, loss_f: 3.8914315700531006\n",
      "epoch : 5\n",
      "-1.651500940322876\n",
      "-2.235330581665039\n",
      "-2.9525442123413086\n",
      "-3.867929697036743\n",
      "-5.10163688659668\n",
      "loss_g: -5.10163688659668, loss_f: 2.6839659214019775\n",
      "epoch : 6\n",
      "-3.7869927883148193\n",
      "-4.540798187255859\n",
      "-5.491685390472412\n",
      "-6.722943305969238\n",
      "-8.361311912536621\n",
      "loss_g: -8.361311912536621, loss_f: -1.7186726331710815\n",
      "epoch : 7\n",
      "40.667232513427734\n",
      "10.06761646270752\n",
      "5.0710296630859375\n",
      "3.099928140640259\n",
      "1.9688899517059326\n",
      "loss_g: 1.9688899517059326, loss_f: 13.64122486114502\n",
      "epoch : 8\n",
      "0.7112570405006409\n",
      "0.4817001223564148\n",
      "0.33250436186790466\n",
      "0.2791024446487427\n",
      "0.27395597100257874\n",
      "loss_g: 0.27395597100257874, loss_f: 10.566709518432617\n",
      "epoch : 9\n",
      "0.17293605208396912\n",
      "0.1728362739086151\n",
      "0.11081110686063766\n",
      "0.0977039486169815\n",
      "0.09120400995016098\n",
      "loss_g: 0.09120400995016098, loss_f: 6.840768814086914\n",
      "epoch : 10\n",
      "0.02736634761095047\n",
      "-0.01536717638373375\n",
      "-0.029266269877552986\n",
      "-0.04093015193939209\n",
      "-0.05214738845825195\n",
      "loss_g: -0.05214738845825195, loss_f: 3.380632162094116\n",
      "epoch : 11\n",
      "-0.2760776877403259\n",
      "-0.4157736897468567\n",
      "-0.5632320046424866\n",
      "-0.7245386242866516\n",
      "-0.9062631130218506\n",
      "loss_g: -0.9062631130218506, loss_f: 0.5386691689491272\n",
      "epoch : 12\n",
      "-1.7061346769332886\n",
      "-2.25773549079895\n",
      "-2.949486255645752\n",
      "-3.8503663539886475\n",
      "-5.067322254180908\n",
      "loss_g: -5.067322254180908, loss_f: 0.2413329929113388\n",
      "epoch : 13\n",
      "-5.762739181518555\n",
      "-7.603643417358398\n",
      "-10.31583309173584\n",
      "-14.577054023742676\n",
      "-21.8195743560791\n",
      "loss_g: -21.8195743560791, loss_f: 4.414255142211914\n",
      "epoch : 14\n",
      "103.12389373779297\n",
      "5.0854363441467285\n",
      "2.3543412685394287\n",
      "1.6740339994430542\n",
      "1.279245138168335\n",
      "loss_g: 1.279245138168335, loss_f: 15.303526878356934\n",
      "epoch : 15\n",
      "0.7406724095344543\n",
      "0.6222206354141235\n",
      "0.5661450028419495\n",
      "0.5605272054672241\n",
      "0.43782883882522583\n",
      "loss_g: 0.43782883882522583, loss_f: 12.383905410766602\n",
      "epoch : 16\n",
      "0.2881147861480713\n",
      "0.23374687135219574\n",
      "0.22511322796344757\n",
      "0.25595536828041077\n",
      "0.2756660282611847\n",
      "loss_g: 0.2756660282611847, loss_f: 9.8849515914917\n",
      "epoch : 17\n",
      "0.11466734111309052\n",
      "0.11325851827859879\n",
      "0.08437427878379822\n",
      "0.08381503820419312\n",
      "0.08761130273342133\n",
      "loss_g: 0.08761130273342133, loss_f: 7.54427433013916\n",
      "epoch : 18\n",
      "0.007308751344680786\n",
      "-0.015589097514748573\n",
      "-0.03163943067193031\n",
      "-0.03570722043514252\n",
      "-0.027136383578181267\n",
      "loss_g: -0.027136383578181267, loss_f: 5.517082691192627\n",
      "epoch : 19\n",
      "-0.17678402364253998\n",
      "-0.20141656696796417\n",
      "-0.22871482372283936\n",
      "-0.25632405281066895\n",
      "-0.2848241329193115\n",
      "loss_g: -0.2848241329193115, loss_f: 3.803241014480591\n",
      "epoch : 20\n",
      "-0.49574175477027893\n",
      "-0.5669694542884827\n",
      "-0.6422202587127686\n",
      "-0.722153902053833\n",
      "-0.8082285523414612\n",
      "loss_g: -0.8082285523414612, loss_f: 2.508186101913452\n",
      "epoch : 21\n",
      "-1.1571587324142456\n",
      "-1.3356633186340332\n",
      "-1.537460207939148\n",
      "-1.7672683000564575\n",
      "-2.0309507846832275\n",
      "loss_g: -2.0309507846832275, loss_f: 1.9569975137710571\n",
      "epoch : 22\n",
      "-2.544121265411377\n",
      "-2.9700851440429688\n",
      "-3.4776451587677\n",
      "-4.090893268585205\n",
      "-4.841292858123779\n",
      "loss_g: -4.841292858123779, loss_f: 2.748490333557129\n",
      "epoch : 23\n",
      "-4.712946891784668\n",
      "-5.532629013061523\n",
      "-6.525434970855713\n",
      "-7.777398586273193\n",
      "-9.422242164611816\n",
      "loss_g: -9.422242164611816, loss_f: 3.599273204803467\n",
      "epoch : 24\n",
      "-1.2469291687011719\n",
      "-1.5128592252731323\n",
      "-1.751826524734497\n",
      "-2.0001108646392822\n",
      "-2.288623571395874\n",
      "loss_g: -2.288623571395874, loss_f: -7.30112886428833\n",
      "epoch : 25\n",
      "13.641220092773438\n",
      "10.598732948303223\n",
      "8.438279151916504\n",
      "6.7405219078063965\n",
      "5.455370903015137\n",
      "loss_g: 5.455370903015137, loss_f: -4.516995906829834\n",
      "epoch : 26\n",
      "5.938589572906494\n",
      "4.632867336273193\n",
      "3.4233450889587402\n",
      "1.9005118608474731\n",
      "0.480235755443573\n",
      "loss_g: 0.480235755443573, loss_f: 3.385284900665283\n",
      "epoch : 27\n",
      "0.08325488120317459\n",
      "-0.4214792847633362\n",
      "-0.8338246941566467\n",
      "-1.1844241619110107\n",
      "-1.5300785303115845\n",
      "loss_g: -1.5300785303115845, loss_f: 4.319328784942627\n",
      "epoch : 28\n",
      "-0.13929738104343414\n",
      "-0.2670542299747467\n",
      "-0.37549343705177307\n",
      "-0.47492218017578125\n",
      "-0.563944399356842\n",
      "loss_g: -0.563944399356842, loss_f: 3.0157418251037598\n",
      "epoch : 29\n",
      "1.530301809310913\n",
      "1.4437443017959595\n",
      "1.373958945274353\n",
      "1.3097271919250488\n",
      "1.2497706413269043\n",
      "loss_g: 1.2497706413269043, loss_f: 1.8701128959655762\n",
      "epoch : 30\n",
      "2.4917993545532227\n",
      "2.3066439628601074\n",
      "2.138470411300659\n",
      "1.9841609001159668\n",
      "1.8420379161834717\n",
      "loss_g: 1.8420379161834717, loss_f: 1.9784809350967407\n",
      "epoch : 31\n",
      "2.0799829959869385\n",
      "1.9008865356445312\n",
      "1.737450122833252\n",
      "1.5893160104751587\n",
      "1.4548132419586182\n",
      "loss_g: 1.4548132419586182, loss_f: 2.3573877811431885\n",
      "epoch : 32\n",
      "1.2885881662368774\n",
      "1.1783571243286133\n",
      "1.0754114389419556\n",
      "0.9789942502975464\n",
      "0.8886122107505798\n",
      "loss_g: 0.8886122107505798, loss_f: 2.3136353492736816\n",
      "epoch : 33\n",
      "0.662446141242981\n",
      "0.6030126214027405\n",
      "0.5459466576576233\n",
      "0.4912183880805969\n",
      "0.4387030303478241\n",
      "loss_g: 0.4387030303478241, loss_f: 1.7999359369277954\n",
      "epoch : 34\n",
      "0.251646488904953\n",
      "0.21928304433822632\n",
      "0.18458685278892517\n",
      "0.14928780496120453\n",
      "0.11082179099321365\n",
      "loss_g: 0.11082179099321365, loss_f: 0.9664315581321716\n",
      "epoch : 35\n",
      "-0.05897486209869385\n",
      "-0.10381874442100525\n",
      "-0.14951547980308533\n",
      "-0.1998288333415985\n",
      "-0.2715674638748169\n",
      "loss_g: -0.2715674638748169, loss_f: 0.1082933098077774\n",
      "epoch : 36\n",
      "-0.4919777810573578\n",
      "-0.5915306210517883\n",
      "-0.7115597128868103\n",
      "-0.8349105715751648\n",
      "-0.9607652425765991\n",
      "loss_g: -0.9607652425765991, loss_f: -0.5001576542854309\n",
      "epoch : 37\n",
      "-1.2812610864639282\n",
      "-1.455088496208191\n",
      "-1.6466747522354126\n",
      "-1.8589571714401245\n",
      "-2.0957908630371094\n",
      "loss_g: -2.0957908630371094, loss_f: -0.773777425289154\n",
      "epoch : 38\n",
      "-2.642810821533203\n",
      "-3.033737897872925\n",
      "-3.493682861328125\n",
      "-4.0353617668151855\n",
      "-4.672043323516846\n",
      "loss_g: -4.672043323516846, loss_f: 0.41054677963256836\n",
      "epoch : 39\n",
      "-5.600008964538574\n",
      "-6.660176753997803\n",
      "-8.117232322692871\n",
      "-10.17731761932373\n",
      "-13.290607452392578\n",
      "loss_g: -13.290607452392578, loss_f: 8.624581336975098\n",
      "epoch : 40\n",
      "-13.305459976196289\n",
      "-17.959156036376953\n",
      "-25.47981834411621\n",
      "-39.1829833984375\n",
      "-68.53034210205078\n",
      "loss_g: -68.53034210205078, loss_f: 73.83362579345703\n",
      "epoch : 41\n",
      "350.0590515136719\n",
      "8.818940162658691\n",
      "7.166561603546143\n",
      "5.8059773445129395\n",
      "4.727849960327148\n",
      "loss_g: 4.727849960327148, loss_f: 11.94672966003418\n",
      "epoch : 42\n",
      "3.5418190956115723\n",
      "2.929825782775879\n",
      "2.4095041751861572\n",
      "1.9549280405044556\n",
      "1.5477818250656128\n",
      "loss_g: 1.5477818250656128, loss_f: 13.563788414001465\n",
      "epoch : 43\n",
      "1.0411409139633179\n",
      "0.7357516884803772\n",
      "0.47309041023254395\n",
      "0.2666802406311035\n",
      "0.15652699768543243\n",
      "loss_g: 0.15652699768543243, loss_f: 13.283452987670898\n",
      "epoch : 44\n",
      "0.0475945919752121\n",
      "0.0008212272077798843\n",
      "-0.03121558390557766\n",
      "-0.05264855921268463\n",
      "-0.07205356657505035\n",
      "loss_g: -0.07205356657505035, loss_f: 11.990884780883789\n",
      "epoch : 45\n",
      "-0.12804459035396576\n",
      "-0.1557004302740097\n",
      "-0.1838541179895401\n",
      "-0.21233057975769043\n",
      "-0.24124760925769806\n",
      "loss_g: -0.24124760925769806, loss_f: 10.807262420654297\n",
      "epoch : 46\n",
      "-0.3170243799686432\n",
      "-0.35687875747680664\n",
      "-0.3980456590652466\n",
      "-0.440528005361557\n",
      "-0.4845118522644043\n",
      "loss_g: -0.4845118522644043, loss_f: 9.792586326599121\n",
      "epoch : 47\n",
      "-0.5790006518363953\n",
      "-0.6355646848678589\n",
      "-0.6942108273506165\n",
      "-0.7551694512367249\n",
      "-0.8186073899269104\n",
      "loss_g: -0.8186073899269104, loss_f: 8.917327880859375\n",
      "epoch : 48\n",
      "-0.9187197685241699\n",
      "-0.9926490187644958\n",
      "-1.0691776275634766\n",
      "-1.1487153768539429\n",
      "-1.2314945459365845\n",
      "loss_g: -1.2314945459365845, loss_f: 8.148096084594727\n",
      "epoch : 49\n",
      "-1.3058825731277466\n",
      "-1.394791841506958\n",
      "-1.4874643087387085\n",
      "-1.5839520692825317\n",
      "-1.6847132444381714\n",
      "loss_g: -1.6847132444381714, loss_f: 7.391578197479248\n",
      "epoch : 50\n",
      "-1.6870728731155396\n",
      "-1.7871222496032715\n",
      "-1.8924896717071533\n",
      "-2.0028979778289795\n",
      "-2.118464708328247\n",
      "loss_g: -2.118464708328247, loss_f: 6.57034158706665\n",
      "epoch : 51\n",
      "-1.9762483835220337\n",
      "-2.0790975093841553\n",
      "-2.1875109672546387\n",
      "-2.301737070083618\n",
      "-2.4232475757598877\n",
      "loss_g: -2.4232475757598877, loss_f: 5.603031158447266\n",
      "epoch : 52\n",
      "-2.0387208461761475\n",
      "-2.1255037784576416\n",
      "-2.216510057449341\n",
      "-2.312182903289795\n",
      "-2.4127001762390137\n",
      "loss_g: -2.4127001762390137, loss_f: 4.442676067352295\n",
      "epoch : 53\n",
      "-1.7080539464950562\n",
      "-1.7629843950271606\n",
      "-1.8201135396957397\n",
      "-1.879294514656067\n",
      "-1.940043568611145\n",
      "loss_g: -1.940043568611145, loss_f: 3.116647958755493\n",
      "epoch : 54\n",
      "-0.9078624844551086\n",
      "-0.9285305738449097\n",
      "-0.9498725533485413\n",
      "-0.9711893796920776\n",
      "-0.9915953874588013\n",
      "loss_g: -0.9915953874588013, loss_f: 1.8470609188079834\n",
      "epoch : 55\n",
      "0.2151101678609848\n",
      "0.2047608196735382\n",
      "0.19580703973770142\n",
      "0.18737168610095978\n",
      "0.1796400249004364\n",
      "loss_g: 0.1796400249004364, loss_f: 0.9628278017044067\n",
      "epoch : 56\n",
      "1.3169912099838257\n",
      "1.282826542854309\n",
      "1.2498779296875\n",
      "1.2178322076797485\n",
      "1.1868042945861816\n",
      "loss_g: 1.1868042945861816, loss_f: 0.7357975244522095\n",
      "epoch : 57\n",
      "2.045158863067627\n",
      "1.9723873138427734\n",
      "1.9024224281311035\n",
      "1.8350160121917725\n",
      "1.7702319622039795\n",
      "loss_g: 1.7702319622039795, loss_f: 1.1128814220428467\n",
      "epoch : 58\n",
      "2.2943997383117676\n",
      "2.1987969875335693\n",
      "2.10736346244812\n",
      "2.018702983856201\n",
      "1.9343583583831787\n",
      "loss_g: 1.9343583583831787, loss_f: 1.8009382486343384\n",
      "epoch : 59\n",
      "2.179391622543335\n",
      "2.080071449279785\n",
      "1.985704779624939\n",
      "1.8964381217956543\n",
      "1.8119174242019653\n",
      "loss_g: 1.8119174242019653, loss_f: 2.545426607131958\n",
      "epoch : 60\n",
      "1.8811283111572266\n",
      "1.7955479621887207\n",
      "1.7147997617721558\n",
      "1.6381601095199585\n",
      "1.565508484840393\n",
      "loss_g: 1.565508484840393, loss_f: 3.1607542037963867\n",
      "epoch : 61\n",
      "1.5422250032424927\n",
      "1.475191593170166\n",
      "1.4109383821487427\n",
      "1.3498457670211792\n",
      "1.2921204566955566\n",
      "loss_g: 1.2921204566955566, loss_f: 3.594144821166992\n",
      "epoch : 62\n",
      "1.224974274635315\n",
      "1.1750675439834595\n",
      "1.1272481679916382\n",
      "1.0815255641937256\n",
      "1.0380092859268188\n",
      "loss_g: 1.0380092859268188, loss_f: 3.8320183753967285\n",
      "epoch : 63\n",
      "0.9583450555801392\n",
      "0.9225220680236816\n",
      "0.8878813982009888\n",
      "0.854369044303894\n",
      "0.8218737244606018\n",
      "loss_g: 0.8218737244606018, loss_f: 3.894535779953003\n",
      "epoch : 64\n",
      "0.7411998510360718\n",
      "0.7141702771186829\n",
      "0.6876429915428162\n",
      "0.6615396738052368\n",
      "0.6360369920730591\n",
      "loss_g: 0.6360369920730591, loss_f: 3.831164598464966\n",
      "epoch : 65\n",
      "0.5592525005340576\n",
      "0.5373018383979797\n",
      "0.5157289505004883\n",
      "0.4944383203983307\n",
      "0.47363102436065674\n",
      "loss_g: 0.47363102436065674, loss_f: 3.6811492443084717\n",
      "epoch : 66\n",
      "0.4015563130378723\n",
      "0.3836505711078644\n",
      "0.3665580451488495\n",
      "0.3511195778846741\n",
      "0.3364517092704773\n",
      "loss_g: 0.3364517092704773, loss_f: 3.472395896911621\n",
      "epoch : 67\n",
      "0.27111828327178955\n",
      "0.25865164399147034\n",
      "0.24700996279716492\n",
      "0.23548483848571777\n",
      "0.2243182361125946\n",
      "loss_g: 0.2243182361125946, loss_f: 3.218808650970459\n",
      "epoch : 68\n",
      "0.16293945908546448\n",
      "0.15250399708747864\n",
      "0.14257673919200897\n",
      "0.13343456387519836\n",
      "0.1247466504573822\n",
      "loss_g: 0.1247466504573822, loss_f: 2.9248251914978027\n",
      "epoch : 69\n",
      "0.06629809737205505\n",
      "0.05767717957496643\n",
      "0.04918408393859863\n",
      "0.0409344807267189\n",
      "0.033067189157009125\n",
      "loss_g: 0.033067189157009125, loss_f: 2.5997507572174072\n",
      "epoch : 70\n",
      "-0.02704661339521408\n",
      "-0.03622683137655258\n",
      "-0.0452360101044178\n",
      "-0.053985051810741425\n",
      "-0.06316985934972763\n",
      "loss_g: -0.06316985934972763, loss_f: 2.2486634254455566\n",
      "epoch : 71\n",
      "-0.132017120718956\n",
      "-0.14769499003887177\n",
      "-0.16477161645889282\n",
      "-0.1827923059463501\n",
      "-0.20120112597942352\n",
      "loss_g: -0.20120112597942352, loss_f: 1.8787474632263184\n",
      "epoch : 72\n",
      "-0.2879965305328369\n",
      "-0.3142642378807068\n",
      "-0.34096792340278625\n",
      "-0.36821305751800537\n",
      "-0.3958949148654938\n",
      "loss_g: -0.3958949148654938, loss_f: 1.5100599527359009\n",
      "epoch : 73\n",
      "-0.5003149509429932\n",
      "-0.5357670783996582\n",
      "-0.571300208568573\n",
      "-0.6077341437339783\n",
      "-0.6451557278633118\n",
      "loss_g: -0.6451557278633118, loss_f: 1.1443536281585693\n",
      "epoch : 74\n",
      "-0.7658445835113525\n",
      "-0.814345121383667\n",
      "-0.8645607829093933\n",
      "-0.9161202311515808\n",
      "-0.9684473872184753\n",
      "loss_g: -0.9684473872184753, loss_f: 0.7877488732337952\n",
      "epoch : 75\n",
      "-1.1020551919937134\n",
      "-1.1673617362976074\n",
      "-1.2355430126190186\n",
      "-1.3068664073944092\n",
      "-1.3815830945968628\n",
      "loss_g: -1.3815830945968628, loss_f: 0.42590922117233276\n",
      "epoch : 76\n",
      "-1.5159549713134766\n",
      "-1.6051422357559204\n",
      "-1.6995797157287598\n",
      "-1.799483299255371\n",
      "-1.905266523361206\n",
      "loss_g: -1.905266523361206, loss_f: 0.03260970115661621\n",
      "epoch : 77\n",
      "-2.0052573680877686\n",
      "-2.122987747192383\n",
      "-2.24851131439209\n",
      "-2.3824052810668945\n",
      "-2.525434970855713\n",
      "loss_g: -2.525434970855713, loss_f: -0.45710688829421997\n",
      "epoch : 78\n",
      "-2.5040481090545654\n",
      "-2.649198055267334\n",
      "-2.8046131134033203\n",
      "-2.9713029861450195\n",
      "-3.150984048843384\n",
      "loss_g: -3.150984048843384, loss_f: -1.168065071105957\n",
      "epoch : 79\n",
      "-2.830930471420288\n",
      "-2.985966920852661\n",
      "-3.1521761417388916\n",
      "-3.330688953399658\n",
      "-3.523033380508423\n",
      "loss_g: -3.523033380508423, loss_f: -2.290766716003418\n",
      "epoch : 80\n",
      "-2.61661696434021\n",
      "-2.7435271739959717\n",
      "-2.8776943683624268\n",
      "-3.020092487335205\n",
      "-3.17022967338562\n",
      "loss_g: -3.17022967338562, loss_f: -3.8959457874298096\n",
      "epoch : 81\n",
      "-1.436544418334961\n",
      "-1.5202449560165405\n",
      "-1.6079270839691162\n",
      "-1.6998289823532104\n",
      "-1.7963709831237793\n",
      "loss_g: -1.7963709831237793, loss_f: -5.336988925933838\n",
      "epoch : 82\n",
      "0.37589016556739807\n",
      "0.224003404378891\n",
      "0.0722498968243599\n",
      "-0.07992270588874817\n",
      "-0.23316004872322083\n",
      "loss_g: -0.23316004872322083, loss_f: -5.210317134857178\n",
      "epoch : 83\n",
      "1.351865291595459\n",
      "1.0807178020477295\n",
      "0.8209988474845886\n",
      "0.5733624696731567\n",
      "0.33823099732398987\n",
      "loss_g: 0.33823099732398987, loss_f: -3.3515567779541016\n",
      "epoch : 84\n",
      "0.9854567646980286\n",
      "0.6807701587677002\n",
      "0.4002927541732788\n",
      "0.15128293633460999\n",
      "-0.07511886954307556\n",
      "loss_g: -0.07511886954307556, loss_f: -0.9009049534797668\n",
      "epoch : 85\n",
      "0.008425984531641006\n",
      "-0.1583288013935089\n",
      "-0.2804841697216034\n",
      "-0.3737632930278778\n",
      "-0.44509994983673096\n",
      "loss_g: -0.44509994983673096, loss_f: 0.3414049446582794\n",
      "epoch : 86\n",
      "-0.3994986414909363\n",
      "-0.4512800872325897\n",
      "-0.4952487349510193\n",
      "-0.5302960872650146\n",
      "-0.5631067156791687\n",
      "loss_g: -0.5631067156791687, loss_f: 0.7387610077857971\n",
      "epoch : 87\n",
      "-0.4844435751438141\n",
      "-0.5085481405258179\n",
      "-0.532157301902771\n",
      "-0.5549833178520203\n",
      "-0.5776689052581787\n",
      "loss_g: -0.5776689052581787, loss_f: 0.6964353919029236\n",
      "epoch : 88\n",
      "-0.42631739377975464\n",
      "-0.44345104694366455\n",
      "-0.45998063683509827\n",
      "-0.4754519462585449\n",
      "-0.4896109998226166\n",
      "loss_g: -0.4896109998226166, loss_f: 0.44073188304901123\n",
      "epoch : 89\n",
      "-0.24874858558177948\n",
      "-0.2538915276527405\n",
      "-0.2578924596309662\n",
      "-0.2603236734867096\n",
      "-0.2622873783111572\n",
      "loss_g: -0.2622873783111572, loss_f: 0.033174410462379456\n",
      "epoch : 90\n",
      "0.09690670669078827\n",
      "0.10148888826370239\n",
      "0.10638611018657684\n",
      "0.11052387207746506\n",
      "0.11540158092975616\n",
      "loss_g: 0.11540158092975616, loss_f: -0.399803102016449\n",
      "epoch : 91\n",
      "0.5630390644073486\n",
      "0.5666061043739319\n",
      "0.569819986820221\n",
      "0.5726346969604492\n",
      "0.5749760270118713\n",
      "loss_g: 0.5749760270118713, loss_f: -0.6532303690910339\n",
      "epoch : 92\n",
      "1.043312907218933\n",
      "1.0377565622329712\n",
      "1.0328501462936401\n",
      "1.027172327041626\n",
      "1.0212080478668213\n",
      "loss_g: 1.0212080478668213, loss_f: -0.6857381463050842\n",
      "epoch : 93\n",
      "1.432955026626587\n",
      "1.414455771446228\n",
      "1.3963093757629395\n",
      "1.3785239458084106\n",
      "1.3608869314193726\n",
      "loss_g: 1.3608869314193726, loss_f: -0.46161144971847534\n",
      "epoch : 94\n",
      "1.6706702709197998\n",
      "1.6415798664093018\n",
      "1.6136572360992432\n",
      "1.586867332458496\n",
      "1.560311198234558\n",
      "loss_g: 1.560311198234558, loss_f: -0.1118152067065239\n",
      "epoch : 95\n",
      "1.7630445957183838\n",
      "1.7309536933898926\n",
      "1.6997491121292114\n",
      "1.669722080230713\n",
      "1.6426767110824585\n",
      "loss_g: 1.6426767110824585, loss_f: 0.29505714774131775\n",
      "epoch : 96\n",
      "1.754507303237915\n",
      "1.7212885618209839\n",
      "1.691340446472168\n",
      "1.661622166633606\n",
      "1.633307695388794\n",
      "loss_g: 1.633307695388794, loss_f: 0.7141985297203064\n",
      "epoch : 97\n",
      "1.6692874431610107\n",
      "1.6406328678131104\n",
      "1.6110031604766846\n",
      "1.5803062915802002\n",
      "1.5463002920150757\n",
      "loss_g: 1.5463002920150757, loss_f: 1.1562734842300415\n",
      "epoch : 98\n",
      "1.5146435499191284\n",
      "1.4840152263641357\n",
      "1.4531410932540894\n",
      "1.4231417179107666\n",
      "1.3923027515411377\n",
      "loss_g: 1.3923027515411377, loss_f: 1.5705914497375488\n",
      "epoch : 99\n",
      "1.3165205717086792\n",
      "1.2901970148086548\n",
      "1.2625657320022583\n",
      "1.236384391784668\n",
      "1.2079153060913086\n",
      "loss_g: 1.2079153060913086, loss_f: 1.923073410987854\n",
      "epoch : 100\n",
      "1.1029245853424072\n",
      "1.0816272497177124\n",
      "1.0592008829116821\n",
      "1.037176489830017\n",
      "1.0155550241470337\n",
      "loss_g: 1.0155550241470337, loss_f: 2.1710822582244873\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=501, shuffle=True)\n",
    "\n",
    "loss_f = list()\n",
    "loss_g = list()\n",
    "\n",
    "prev_param_f = [param.clone().detach() for param in ICNNf.parameters()]\n",
    "prev_param_g = [param.clone().detach() for param in ICNNg.parameters()]\n",
    "\n",
    "for epoch in range(1, 101) :\n",
    "    print('epoch :', epoch)\n",
    "    mean_loss_f, mean_loss_g, prev_param_f, prev_param_g = train_makkuva_epoch(ICNNf=ICNNf, ICNNg=ICNNg, prev_param_f=prev_param_f, prev_param_g=prev_param_g, dataloader = dataloader, init_z_f = init_z_f, init_z_g = init_z_g, lr=0.0005, train_freq_g=5, train_freq_f=1, regularize_f = True, regularize_g = True, lambda_proximal = 0.0001)\n",
    "    #mean_loss_f, mean_loss_g = train_makkuva_epoch(ICNNf, ICNNg, None, None, dataloader, init_z_f = lambda x: (1/2) * torch.norm(x, dim=-1, keepdim=True)**2, init_z_g = lambda x: (1/2) * torch.norm(-x, dim=-1, keepdim=True)**2, lr=0.0001, train_freq_g=10, train_freq_f=1, gaussian_transport=False)\n",
    "\n",
    "    loss_f.append(mean_loss_f)\n",
    "    loss_g.append(mean_loss_g)\n",
    "\n",
    "    filename_pth_f = filepath_pth_f + str(epoch) + '.pth'\n",
    "    filename_pth_g = filepath_pth_g + str(epoch) + '.pth'\n",
    "    torch.save(ICNNf.state_dict(), filename_pth_f)\n",
    "    torch.save(ICNNg.state_dict(), filename_pth_g)\n",
    "\n",
    "    filename_plt_f = filepath_plt_f + str(epoch) + '.png'\n",
    "    filename_plt_g = filepath_plt_g + str(epoch) + '.png'\n",
    "    plot_transport(dataset, test, ICNNf, ICNNg, init_z_f=init_z_f, init_z_g=init_z_g, filename_f = filename_plt_f, filename_g = filename_plt_g, n_points=n_points)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0\n",
      "epoch : 100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "l_test = [12, 13, 14, 15, 16, 17, 18, 19]\n",
    "for epoch in [0,100]:\n",
    "    print('epoch :', epoch)\n",
    "\n",
    "    filename_pth_f = filepath_pth_f + str(epoch) + '.pth'\n",
    "    filename_pth_g = filepath_pth_g + str(epoch) + '.pth'\n",
    "\n",
    "    state_dict_init_f = torch.load(filename_pth_f)\n",
    "    state_dict_init_g = torch.load(filename_pth_f)\n",
    "\n",
    "    ICNNf.load_state_dict(state_dict_init_f)\n",
    "    ICNNg.load_state_dict(state_dict_init_g)\n",
    "\n",
    "    for test in l_test :\n",
    "        filename_plt_f = filepath_plt_f + 'test_' + str(test) + '_'  +str(epoch) + '.png'\n",
    "        filename_plt_g = filepath_plt_g + 'test_' + str(test) + '_' + str(epoch) + '.png'\n",
    "        plot_transport(dataset, test, ICNNf, ICNNg, init_z_f=init_z_f, init_z_g=init_z_g, filename_f = filename_plt_f, filename_g = filename_plt_g, n_points=n_points)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained_models/training22/plots/model_f_test_19_100.png\n"
     ]
    }
   ],
   "source": [
    "print(filename_plt_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.093396186828613\n",
      "10.272769927978516\n",
      "8.232588768005371\n",
      "3.8914315700531006\n",
      "2.6839659214019775\n",
      "-1.7186726331710815\n",
      "13.64122486114502\n",
      "10.566709518432617\n",
      "6.840768814086914\n",
      "3.380632162094116\n",
      "0.5386691689491272\n",
      "0.2413329929113388\n",
      "4.414255142211914\n",
      "15.303526878356934\n",
      "12.383905410766602\n",
      "9.8849515914917\n",
      "7.54427433013916\n",
      "5.517082691192627\n",
      "3.803241014480591\n",
      "2.508186101913452\n",
      "1.9569975137710571\n",
      "2.748490333557129\n",
      "3.599273204803467\n",
      "-7.30112886428833\n",
      "-4.516995906829834\n",
      "3.385284900665283\n",
      "4.319328784942627\n",
      "3.0157418251037598\n",
      "1.8701128959655762\n",
      "1.9784809350967407\n",
      "2.3573877811431885\n",
      "2.3136353492736816\n",
      "1.7999359369277954\n",
      "0.9664315581321716\n",
      "0.1082933098077774\n",
      "-0.5001576542854309\n",
      "-0.773777425289154\n",
      "0.41054677963256836\n",
      "8.624581336975098\n",
      "73.83362579345703\n",
      "11.94672966003418\n",
      "13.563788414001465\n",
      "13.283452987670898\n",
      "11.990884780883789\n",
      "10.807262420654297\n",
      "9.792586326599121\n",
      "8.917327880859375\n",
      "8.148096084594727\n",
      "7.391578197479248\n",
      "6.57034158706665\n",
      "5.603031158447266\n",
      "4.442676067352295\n",
      "3.116647958755493\n",
      "1.8470609188079834\n",
      "0.9628278017044067\n",
      "0.7357975244522095\n",
      "1.1128814220428467\n",
      "1.8009382486343384\n",
      "2.545426607131958\n",
      "3.1607542037963867\n",
      "3.594144821166992\n",
      "3.8320183753967285\n",
      "3.894535779953003\n",
      "3.831164598464966\n",
      "3.6811492443084717\n",
      "3.472395896911621\n",
      "3.218808650970459\n",
      "2.9248251914978027\n",
      "2.5997507572174072\n",
      "2.2486634254455566\n",
      "1.8787474632263184\n",
      "1.5100599527359009\n",
      "1.1443536281585693\n",
      "0.7877488732337952\n",
      "0.42590922117233276\n",
      "0.03260970115661621\n",
      "-0.45710688829421997\n",
      "-1.168065071105957\n",
      "-2.290766716003418\n",
      "-3.8959457874298096\n",
      "-5.336988925933838\n",
      "-5.210317134857178\n",
      "-3.3515567779541016\n",
      "-0.9009049534797668\n",
      "0.3414049446582794\n",
      "0.7387610077857971\n",
      "0.6964353919029236\n",
      "0.44073188304901123\n",
      "0.033174410462379456\n",
      "-0.399803102016449\n",
      "-0.6532303690910339\n",
      "-0.6857381463050842\n",
      "-0.46161144971847534\n",
      "-0.1118152067065239\n",
      "0.29505714774131775\n",
      "0.7141985297203064\n",
      "1.1562734842300415\n",
      "1.5705914497375488\n",
      "1.923073410987854\n",
      "2.1710822582244873\n"
     ]
    }
   ],
   "source": [
    "for ele in loss_f:\n",
    "    print(ele)\n",
    "\n",
    "# print('stop')\n",
    "\n",
    "# for ele in loss_g:\n",
    "#     print(ele)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
