{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Imports__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import scipy.stats as stats\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchviz import make_dot\n",
    "\n",
    "from icnnet import ICNNet\n",
    "from mydataset import MyDataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Toy data TR 1D__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.0661],\n",
      "        [-1.0001],\n",
      "        [-0.9680],\n",
      "        ...,\n",
      "        [ 0.9911],\n",
      "        [ 1.0228],\n",
      "        [ 0.8575]])\n"
     ]
    }
   ],
   "source": [
    "n = 1000\n",
    "\n",
    "x = torch.concat([torch.tensor(stats.norm.rvs(loc=-1, scale=0.1, size=(n,1)), dtype=torch.float32), torch.tensor(stats.norm.rvs(loc=1, scale=0.1, size=(n,1)), dtype=torch.float32)])\n",
    "#y = torch.concat([torch.zeros(n//2), torch.ones(n//2), torch.zeros(n//2), torch.ones(n//2)])\n",
    "#c = torch.concat([torch.zeros(n//2), torch.ones(n//2), torch.zeros(n//2), torch.ones(n//2)])\n",
    "\n",
    "y = torch.concat([-torch.ones(n), torch.ones(n)])\n",
    "c = torch.concat([torch.ones(2*n)])\n",
    "\n",
    "X = torch.stack(torch.unbind(x,dim=0))\n",
    "Y = torch.stack(torch.unbind(y,dim=0)).unsqueeze(1)\n",
    "C = torch.stack(torch.unbind(c,dim=0)).unsqueeze(1)\n",
    "\n",
    "print(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Toy data valou 1D__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.5050],\n",
      "        [-0.7328],\n",
      "        [-0.7697],\n",
      "        ...,\n",
      "        [-0.4425],\n",
      "        [-1.0191],\n",
      "        [-2.0095]])\n",
      "tensor([[ 1.],\n",
      "        [ 1.],\n",
      "        [ 1.],\n",
      "        ...,\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        [-1.]])\n",
      "tensor([[-1.5050],\n",
      "        [-0.7328],\n",
      "        [-0.7697],\n",
      "        ...,\n",
      "        [ 0.4425],\n",
      "        [-1.0191],\n",
      "        [ 2.0095]])\n"
     ]
    }
   ],
   "source": [
    "n = 1000\n",
    "\n",
    "x = torch.concat([torch.tensor(stats.norm.rvs(loc=-1, scale=1, size=(2*n,1)), dtype=torch.float32)])\n",
    "#y = torch.concat([torch.zeros(n//2), torch.ones(n//2), torch.zeros(n//2), torch.ones(n//2)])\n",
    "#c = torch.concat([torch.zeros(n//2), torch.ones(n//2), torch.zeros(n//2), torch.ones(n//2)])\n",
    "\n",
    "c = torch.concat([-torch.ones(n), torch.ones(n)])\n",
    "\n",
    "X = torch.stack(torch.unbind(x,dim=0))\n",
    "C = torch.stack(torch.unbind(c,dim=0)).unsqueeze(1)\n",
    "C = C[torch.randperm(C.size(0))]\n",
    "\n",
    "Y = C*X\n",
    "print(X)\n",
    "print(C)\n",
    "print(Y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Toy data Gaussian__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 100, 2])\n",
      "torch.Size([1000, 100, 2])\n",
      "torch.Size([1000, 100, 2])\n"
     ]
    }
   ],
   "source": [
    "d = 2 # dimension of the data\n",
    "r = 100 # number of points to simulate my gaussian\n",
    "N = 1000 # number of samples\n",
    "\n",
    "\n",
    "# simulate the gaussian\n",
    "x = torch.tensor(stats.norm.rvs(loc=0, scale=1, size=(N, r, d)), dtype=torch.float32)\n",
    "locs = torch.randint(-10, 10, (N,), dtype=torch.float32).repeat_interleave(r).view(N, r)\n",
    "scales = 5*torch.rand(N, dtype=torch.float32).repeat_interleave(r).view(N, r)\n",
    "\n",
    "c = torch.stack((locs, scales), dim = 2)\n",
    "\n",
    "locs2D = locs.unsqueeze(-1).expand(-1, -1, d)\n",
    "scales2D = scales.unsqueeze(-1).expand(-1, -1, d)\n",
    "\n",
    "y = torch.tensor(stats.norm.rvs(loc=locs2D, scale=scales2D, size=(N, r, d)), dtype=torch.float32)\n",
    "\n",
    "print(x.size())\n",
    "print(c.size())\n",
    "print(y.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Loading the dataset__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "dataset = MyDataset(x, c, y)\n",
    "\n",
    "batch_size = 100  # Example batch size\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__PICNN training__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (10000x2 and 1x1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[69], line 19\u001b[0m\n\u001b[1;32m     15\u001b[0m c_batch\u001b[38;5;241m.\u001b[39mrequires_grad_(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     17\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad() \u001b[38;5;66;03m# Zero the gradients\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc_batch\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Assuming context c is same as input x\u001b[39;00m\n\u001b[1;32m     21\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(output, y_batch) \u001b[38;5;66;03m# Compute the loss\u001b[39;00m\n\u001b[1;32m     22\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward() \u001b[38;5;66;03m# Backward pass\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/CondOT/condot/lib64/python3.9/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/CondOT/condot/lib64/python3.9/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/CondOT/icnnet.py:53\u001b[0m, in \u001b[0;36mICNNet.forward\u001b[0;34m(self, x, c)\u001b[0m\n\u001b[1;32m     51\u001b[0m         u \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers_v[i](u)\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m : \n\u001b[0;32m---> 53\u001b[0m         z \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers_activation[i](\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers_z[i](z \u001b[38;5;241m*\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers_zu\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mu\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers_x[i](\u001b[38;5;28minput\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers_xu[i](u)) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers_u[i](u))\n\u001b[1;32m     54\u001b[0m         u \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers_v[i](u)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m z\n",
      "File \u001b[0;32m~/Desktop/CondOT/condot/lib64/python3.9/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/CondOT/condot/lib64/python3.9/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/CondOT/condot/lib64/python3.9/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/Desktop/CondOT/condot/lib64/python3.9/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/CondOT/condot/lib64/python3.9/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/CondOT/condot/lib64/python3.9/site-packages/torch/nn/modules/linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (10000x2 and 1x1)"
     ]
    }
   ],
   "source": [
    "from torch import optim\n",
    "epochs = 50\n",
    "\n",
    "# Initialize the model\n",
    "model = ICNNet()\n",
    "model.train()\n",
    "\n",
    "# Define the loss function and the optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for x_batch, c_batch, y_batch in dataloader:\n",
    "        x_batch.requires_grad_(True)\n",
    "        c_batch.requires_grad_(True)\n",
    "\n",
    "        optimizer.zero_grad() # Zero the gradients\n",
    "        \n",
    "        output = model(x_batch, c_batch)  # Assuming context c is same as input x\n",
    "\n",
    "        loss = criterion(output, y_batch) # Compute the loss\n",
    "        loss.backward() # Backward pass\n",
    "\n",
    "        optimizer.step() # Update the parameters\n",
    "        # for layers_k in model.layers_z:\n",
    "        #     for param in layers_k.parameters():\n",
    "        #         param.data.clamp_min_(0)\n",
    "        \n",
    "        #pass\n",
    "\n",
    "    #for name, parameter in model.named_parameters():\n",
    "        #if parameter.requires_grad and parameter.grad is not None:\n",
    "            #grad_norm = parameter.grad.norm().item()\n",
    "            #print(f\"Gradient norm for {name}: {grad_norm}\")\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs} Loss: {loss.item()}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.9659]) tensor([0.9711])\n",
      "tensor([-0.8608]) tensor([-0.8804])\n",
      "tensor([-1.5514]) tensor([-1.5494])\n",
      "tensor([-2.0634]) tensor([-2.0654])\n",
      "tensor([-0.3589]) tensor([-0.3625])\n",
      "tensor([-0.0569]) tensor([-0.0557])\n",
      "tensor([0.2998]) tensor([0.3047])\n",
      "tensor([0.5297]) tensor([0.5354])\n",
      "tensor([-0.1235]) tensor([-0.1228])\n",
      "tensor([0.9448]) tensor([0.9500])\n",
      "tensor([1.9734]) tensor([1.9713])\n",
      "tensor([-0.3519]) tensor([-0.3491])\n",
      "tensor([1.6254]) tensor([1.6264])\n",
      "tensor([2.1131]) tensor([2.1097])\n",
      "tensor([1.3164]) tensor([1.3198])\n",
      "tensor([2.5679]) tensor([2.5597])\n",
      "tensor([0.2010]) tensor([0.2053])\n",
      "tensor([1.0198]) tensor([1.0247])\n",
      "tensor([0.7091]) tensor([0.7148])\n",
      "tensor([-0.9824]) tensor([-0.9785])\n",
      "tensor([1.9971]) tensor([1.9948])\n",
      "tensor([0.9218]) tensor([0.9271])\n",
      "tensor([0.4286]) tensor([0.4341])\n",
      "tensor([2.5955]) tensor([2.5870])\n",
      "tensor([1.0804]) tensor([1.0850])\n",
      "tensor([-0.4405]) tensor([-0.4374])\n",
      "tensor([0.6309]) tensor([0.6259])\n",
      "tensor([-1.2735]) tensor([-1.2702])\n",
      "tensor([-1.1432]) tensor([-1.1396])\n",
      "tensor([-0.7228]) tensor([-0.7189])\n",
      "tensor([2.0839]) tensor([2.0807])\n",
      "tensor([-1.6391]) tensor([-1.6376])\n",
      "tensor([-0.6291]) tensor([-0.6254])\n",
      "tensor([0.9206]) tensor([0.9259])\n",
      "tensor([-1.6319]) tensor([-1.6303])\n",
      "tensor([-2.9500]) tensor([-2.9639])\n",
      "tensor([0.0403]) tensor([0.0431])\n",
      "tensor([-0.7065]) tensor([-0.7027])\n",
      "tensor([-1.0141]) tensor([-1.0103])\n",
      "tensor([-0.7957]) tensor([-0.7918])\n",
      "tensor([0.2658]) tensor([0.2645])\n",
      "tensor([0.9038]) tensor([0.9091])\n",
      "tensor([0.4052]) tensor([0.4027])\n",
      "tensor([0.7738]) tensor([0.7672])\n",
      "tensor([-1.9196]) tensor([-1.9203])\n",
      "tensor([-2.7655]) tensor([-2.7764])\n",
      "tensor([1.9558]) tensor([1.9540])\n",
      "tensor([2.7357]) tensor([2.7256])\n",
      "tensor([-2.2963]) tensor([-2.3008])\n",
      "tensor([1.4277]) tensor([1.4302])\n",
      "tensor([1.2664]) tensor([1.2700])\n",
      "tensor([1.3540]) tensor([1.3571])\n",
      "tensor([0.2139]) tensor([0.2183])\n",
      "tensor([2.5841]) tensor([2.5758])\n",
      "tensor([1.3881]) tensor([1.3910])\n",
      "tensor([0.4797]) tensor([0.4764])\n",
      "tensor([0.8196]) tensor([0.8251])\n",
      "tensor([-0.1159]) tensor([-0.1143])\n",
      "tensor([1.7999]) tensor([1.7995])\n",
      "tensor([2.4123]) tensor([2.4058])\n",
      "tensor([-0.1636]) tensor([-0.1617])\n",
      "tensor([-0.8177]) tensor([-0.8139])\n",
      "tensor([-0.0442]) tensor([-0.0431])\n",
      "tensor([3.1167]) tensor([3.1023])\n",
      "tensor([1.3651]) tensor([1.3681])\n",
      "tensor([-0.4054]) tensor([-0.4024])\n",
      "tensor([-2.1079]) tensor([-2.1104])\n",
      "tensor([-2.3334]) tensor([-2.3383])\n",
      "tensor([0.6248]) tensor([0.6306])\n",
      "tensor([1.5021]) tensor([1.5041])\n",
      "tensor([2.3213]) tensor([2.3158])\n",
      "tensor([0.6594]) tensor([0.6541])\n",
      "tensor([-1.2865]) tensor([-1.2834])\n",
      "tensor([1.6257]) tensor([1.6268])\n",
      "tensor([2.3813]) tensor([2.3751])\n",
      "tensor([1.8724]) tensor([1.8713])\n",
      "tensor([-1.3745]) tensor([-1.3716])\n",
      "tensor([0.0797]) tensor([0.0800])\n",
      "tensor([-1.3821]) tensor([-1.3793])\n",
      "tensor([2.5622]) tensor([2.5541])\n",
      "tensor([-1.6041]) tensor([-1.6024])\n",
      "tensor([-0.2401]) tensor([-0.2378])\n",
      "tensor([1.7975]) tensor([1.7748])\n",
      "tensor([-1.6262]) tensor([-1.6246])\n",
      "tensor([-0.8454]) tensor([-0.8415])\n",
      "tensor([1.1133]) tensor([1.1178])\n",
      "tensor([-0.1105]) tensor([-0.1089])\n",
      "tensor([-2.6090]) tensor([-2.6176])\n",
      "tensor([0.4748]) tensor([0.4715])\n",
      "tensor([0.4953]) tensor([0.5009])\n",
      "tensor([0.9092]) tensor([0.9007])\n",
      "tensor([2.8649]) tensor([2.8534])\n",
      "tensor([-0.9006]) tensor([-0.8968])\n",
      "tensor([-0.9739]) tensor([-0.9701])\n",
      "tensor([-0.7777]) tensor([-0.7738])\n",
      "tensor([2.6804]) tensor([2.6710])\n",
      "tensor([0.7295]) tensor([0.7352])\n",
      "tensor([2.3140]) tensor([2.3086])\n",
      "tensor([1.2985]) tensor([1.3020])\n",
      "tensor([0.3873]) tensor([0.3926])\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for x_batch, c_batch, y_batch in dataloader:\n",
    "        outputs = model(x_batch, c_batch)\n",
    "        for result, y in zip(outputs, y_batch) :\n",
    "            print(result, y)\n",
    "        break\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Makkuva training__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100 loss_g: -14697.9033203125, loss_f: -26.161470413208008\n",
      "Epoch 2/100 loss_g: -13241685114880.0, loss_f: -23073417216.0\n",
      "Epoch 3/100 loss_g: -4.9078584419444326e+17, loss_f: -840131305013248.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 35\u001b[0m\n\u001b[1;32m     33\u001b[0m         optimizer_g\u001b[38;5;241m.\u001b[39mstep() \u001b[38;5;66;03m# Update the parameters\u001b[39;00m\n\u001b[1;32m     34\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m layers_k \u001b[38;5;129;01min\u001b[39;00m ICNNg\u001b[38;5;241m.\u001b[39mlayers_z:\n\u001b[0;32m---> 35\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m param \u001b[38;5;129;01min\u001b[39;00m layers_k\u001b[38;5;241m.\u001b[39mparameters():\n\u001b[1;32m     36\u001b[0m                 param\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mclamp_min_(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x, c, y \u001b[38;5;129;01min\u001b[39;00m dataloader:\n",
      "File \u001b[0;32m~/Desktop/CondOT/condot/lib64/python3.9/site-packages/torch/nn/modules/module.py:2193\u001b[0m, in \u001b[0;36mModule.parameters\u001b[0;34m(self, recurse)\u001b[0m\n\u001b[1;32m   2171\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparameters\u001b[39m(\u001b[38;5;28mself\u001b[39m, recurse: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[Parameter]:\n\u001b[1;32m   2172\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Return an iterator over module parameters.\u001b[39;00m\n\u001b[1;32m   2173\u001b[0m \n\u001b[1;32m   2174\u001b[0m \u001b[38;5;124;03m    This is typically passed to an optimizer.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2191\u001b[0m \n\u001b[1;32m   2192\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2193\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m name, param \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnamed_parameters(recurse\u001b[38;5;241m=\u001b[39mrecurse):\n\u001b[1;32m   2194\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m param\n",
      "File \u001b[0;32m~/Desktop/CondOT/condot/lib64/python3.9/site-packages/torch/nn/modules/module.py:2226\u001b[0m, in \u001b[0;36mModule.named_parameters\u001b[0;34m(self, prefix, recurse, remove_duplicate)\u001b[0m\n\u001b[1;32m   2202\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Return an iterator over module parameters, yielding both the name of the parameter as well as the parameter itself.\u001b[39;00m\n\u001b[1;32m   2203\u001b[0m \n\u001b[1;32m   2204\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2221\u001b[0m \n\u001b[1;32m   2222\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2223\u001b[0m gen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_named_members(\n\u001b[1;32m   2224\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m module: module\u001b[38;5;241m.\u001b[39m_parameters\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[1;32m   2225\u001b[0m     prefix\u001b[38;5;241m=\u001b[39mprefix, recurse\u001b[38;5;241m=\u001b[39mrecurse, remove_duplicate\u001b[38;5;241m=\u001b[39mremove_duplicate)\n\u001b[0;32m-> 2226\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m gen\n",
      "File \u001b[0;32m~/Desktop/CondOT/condot/lib64/python3.9/site-packages/torch/nn/modules/module.py:2161\u001b[0m, in \u001b[0;36mModule._named_members\u001b[0;34m(self, get_members_fn, prefix, recurse, remove_duplicate)\u001b[0m\n\u001b[1;32m   2159\u001b[0m memo \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n\u001b[1;32m   2160\u001b[0m modules \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnamed_modules(prefix\u001b[38;5;241m=\u001b[39mprefix, remove_duplicate\u001b[38;5;241m=\u001b[39mremove_duplicate) \u001b[38;5;28;01mif\u001b[39;00m recurse \u001b[38;5;28;01melse\u001b[39;00m [(prefix, \u001b[38;5;28mself\u001b[39m)]\n\u001b[0;32m-> 2161\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m module_prefix, module \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   2162\u001b[0m     members \u001b[38;5;241m=\u001b[39m get_members_fn(module)\n\u001b[1;32m   2163\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m members:\n",
      "File \u001b[0;32m~/Desktop/CondOT/condot/lib64/python3.9/site-packages/torch/nn/modules/module.py:2367\u001b[0m, in \u001b[0;36mModule.named_modules\u001b[0;34m(self, memo, prefix, remove_duplicate)\u001b[0m\n\u001b[1;32m   2365\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m memo:\n\u001b[1;32m   2366\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m remove_duplicate:\n\u001b[0;32m-> 2367\u001b[0m         \u001b[43mmemo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m   2368\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m prefix, \u001b[38;5;28mself\u001b[39m\n\u001b[1;32m   2369\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m name, module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_modules\u001b[38;5;241m.\u001b[39mitems():\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from torch import optim\n",
    "epochs = 100\n",
    "train_freq_g = 20\n",
    "\n",
    "# Initialize the model\n",
    "input_size = 1\n",
    "ICNNf = ICNNet(layer_sizes = [input_size, 2,2,2,2,1], context_layer_sizes=[1,2,2,2,2,2])\n",
    "\n",
    "output_size = 1\n",
    "ICNNg = ICNNet(layer_sizes = [output_size, 2,2,2,2,1], context_layer_sizes=[1,2,2,2,2,2])\n",
    "\n",
    "# Define the loss function and the optimizer\n",
    "optimizer_f = optim.Adam(ICNNf.parameters())\n",
    "optimizer_g = optim.Adam(ICNNg.parameters())\n",
    "\n",
    "for epoch in range(epochs):\n",
    "   \n",
    "    for _ in range(train_freq_g) :\n",
    "        for x, c, y in dataloader:\n",
    "            optimizer_f.zero_grad() # Zero the gradients\n",
    "            optimizer_g.zero_grad() # Zero the gradients\n",
    "            x.requires_grad_(True)\n",
    "            y.requires_grad_(True)\n",
    "            c.requires_grad_(True)\n",
    "\n",
    "            output_g = ICNNg(y, c)\n",
    "            diff_output_g = torch.autograd.grad(output_g, y, grad_outputs=torch.ones_like(output_g), create_graph=True)[0]\n",
    "            \n",
    "            loss_g = - torch.matmul(y.transpose(0, 1), diff_output_g) - ICNNf(diff_output_g, c)\n",
    "            loss_g = torch.mean(loss_g)\n",
    "            loss_g.backward() # Backward pass\n",
    "\n",
    "            optimizer_g.step() # Update the parameters\n",
    "            for layers_k in ICNNg.layers_z:\n",
    "                for param in layers_k.parameters():\n",
    "                    param.data.clamp_min_(0)\n",
    "\n",
    "    for x, c, y in dataloader:\n",
    "        optimizer_f.zero_grad() # Zero the gradients\n",
    "        optimizer_g.zero_grad()\n",
    "        x.requires_grad_(True)\n",
    "        y.requires_grad_(True)\n",
    "        c.requires_grad_(True)\n",
    "        \n",
    "\n",
    "\n",
    "        output_g = ICNNg(y, c)\n",
    "        diff_output_g = torch.autograd.grad(outputs=output_g, inputs=y, grad_outputs=torch.ones_like(output_g), create_graph=True)[0]\n",
    "\n",
    "        loss_f = ICNNf(x, c) - ICNNf(diff_output_g, c)\n",
    "        loss_f = torch.mean(loss_f)\n",
    "        loss_f.backward() # Backward pass\n",
    "        \n",
    "        for layers_k in ICNNf.layers_z:\n",
    "                for param in layers_k.parameters():\n",
    "                    param.data.clamp_min_(0)\n",
    "\n",
    "\n",
    "        #testing algorithm\n",
    "        output_g_test = ICNNg(x, c)\n",
    "        diff_output_g_test = torch.autograd.grad(output_g_test, x, grad_outputs=torch.ones_like(output_g_test), create_graph=True)[0]\n",
    "\n",
    "        loss_test = diff_output_g_test-y\n",
    "\n",
    "        #print('y =', y[0], 'diff_output_g =', diff_output_g_test[0])\n",
    "        \n",
    "        pass\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs} loss_g: {loss_g.item()}, loss_f: {loss_f.item()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
