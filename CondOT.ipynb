{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100\n",
    "\n",
    "x = torch.concat([torch.tensor(stats.norm.rvs(loc=(-1,-1), scale=1, size=(n,2)), dtype=torch.float32), torch.tensor(stats.norm.rvs(loc=(1,1), scale=1, size=(n,2)), dtype=torch.float32)])\n",
    "y = torch.concat([torch.zeros(n//2), torch.ones(n//2), torch.zeros(n//2), torch.ones(n//2)])\n",
    "c = torch.concat([torch.zeros(n//2), torch.ones(n//2), torch.zeros(n//2), torch.ones(n//2)])\n",
    "\n",
    "X = torch.stack(torch.unbind(x,dim=0))\n",
    "Y = torch.stack(torch.unbind(y,dim=0))\n",
    "C = torch.stack(torch.unbind(c,dim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ICNNet(nn.Module):\n",
    "    def __init__(self, input_size = 2, layer_sizes = [2,32,64,32,8,1], context_layer_sizes=[1,32,64,32,8,1]):\n",
    "        super(ICNNet, self).__init__()\n",
    "        self.n_layers = len(layer_sizes)\n",
    "\n",
    "        self.layers_activation = nn.ModuleList([nn.Softplus() for _ in range(self.n_layers-1)])\n",
    "\n",
    "        self.layers_z = nn.ModuleList([nn.Linear(layer_sizes[i], layer_sizes[i+1], bias=False) for i in range(self.n_layers-1)])\n",
    "\n",
    "        self.layers_zu = nn.ModuleList([nn.Sequential(nn.Linear(context_layer_sizes[i], layer_sizes[i]), nn.ReLU()) for i in range(self.n_layers-1)])\n",
    "\n",
    "        self.layers_x = nn.ModuleList([nn.Linear(input_size, layer_sizes[i+1], bias=False) for i in range(self.n_layers-1)])\n",
    "\n",
    "        self.layers_xu = nn.ModuleList([nn.Linear(context_layer_sizes[i], input_size) for i in range(self.n_layers-1)])\n",
    "\n",
    "        self.layers_u = nn.ModuleList([nn.Linear(context_layer_sizes[i], layer_sizes[i+1]) for i in range(self.n_layers-1)])\n",
    "\n",
    "        self.layers_v = nn.ModuleList([nn.Sequential(nn.Linear(context_layer_sizes[i], context_layer_sizes[i+1]), nn.ReLU()) for i in range(self.n_layers-1)])\n",
    "\n",
    "    def forward(self, x, c):\n",
    "        input = x\n",
    "        u = c\n",
    "        for i in range(self.n_layers-1):\n",
    "            x = self.layers_activation[i](self.layers_z[i](x * self.layers_zu[i](u)) + self.layers_x[i](input * self.layers_xu[i](u)) + self.layers_u[i](u))\n",
    "            u = self.layers_v[i](u)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 Loss: 0.018610745668411255\n",
      "Epoch 2/10 Loss: 0.0027061128057539463\n",
      "Epoch 3/10 Loss: 0.0007559371297247708\n",
      "Epoch 4/10 Loss: 0.00012830697232857347\n",
      "Epoch 5/10 Loss: 3.4207691896881443e-06\n",
      "Epoch 6/10 Loss: 5.353360847948352e-06\n",
      "Epoch 7/10 Loss: 9.492339813732542e-06\n",
      "Epoch 8/10 Loss: 8.261000402853824e-06\n",
      "Epoch 9/10 Loss: 5.956099812465254e-06\n",
      "Epoch 10/10 Loss: 6.11777659287327e-06\n"
     ]
    }
   ],
   "source": [
    "from torch import optim\n",
    "epochs = 100\n",
    "\n",
    "# Initialize the model\n",
    "model = ICNNet()\n",
    "\n",
    "# Define the loss function and the optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for i in range(len(X)):\n",
    "        optimizer.zero_grad() # Zero the gradients\n",
    "        \n",
    "        output = model(X[i].unsqueeze(0), C[i].unsqueeze(0))  # Assuming context c is same as input x\n",
    "\n",
    "        loss = criterion(output, Y[i].unsqueeze(0)) # Compute the loss\n",
    "        loss.backward() # Backward pass\n",
    "        optimizer.step() # Update the parameters\n",
    "\n",
    "        for layers_k in model.layers_z:\n",
    "            for param in layers_k.parameters():\n",
    "                param.data.clamp_min_(0)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs} Loss: {loss.item()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
